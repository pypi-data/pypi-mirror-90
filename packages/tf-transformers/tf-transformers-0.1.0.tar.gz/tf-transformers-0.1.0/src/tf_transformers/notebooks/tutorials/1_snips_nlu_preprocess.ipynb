{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNIPS NLU\n",
    "\n",
    "#### credit -> https://colab.research.google.com/drive/1wgWdxUpKf3FWJgqA6ogBGDEzxAosjJMI\n",
    "\n",
    "Snips NLU consists of 2 tasks (Slot Filling and Classification)\n",
    "\n",
    "Slot filling can be formulated as NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "SNIPS_DATA_BASE_URL = (\n",
    "    \"https://github.com/ogrisel/slot_filling_and_intent_detection_of_SLU/blob/\"\n",
    "    \"master/data/snips/\"\n",
    ")\n",
    "for filename in [\"train\", \"valid\", \"test\", \"vocab.intent\", \"vocab.slot\"]:\n",
    "    path = Path(filename)\n",
    "    if not path.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urlretrieve(SNIPS_DATA_BASE_URL + filename + \"?raw=true\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SNIPS data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def parse_line(line):\n",
    "    utterance_data, intent_label = line.split(\" <=> \")\n",
    "    items = utterance_data.split()\n",
    "    words = [item.rsplit(\":\", 1)[0] for item in items]\n",
    "    word_labels = [item.rsplit(\":\", 1)[1] for item in items]\n",
    "    return {\n",
    "        \"intent_label\": intent_label,\n",
    "        \"words\": \" \".join(words),\n",
    "        \"word_labels\": \" \".join(word_labels),\n",
    "        \"length\": len(words),\n",
    "    }\n",
    "\n",
    "\n",
    "lines_train = Path(\"train\").read_text().strip().splitlines()\n",
    "lines_valid = Path(\"valid\").read_text().strip().splitlines()\n",
    "lines_test = Path(\"test\").read_text().strip().splitlines()\n",
    "\n",
    "df_train = pd.DataFrame([parse_line(line) for line in lines_train])\n",
    "df_valid = pd.DataFrame([parse_line(line) for line in lines_valid])\n",
    "df_test = pd.DataFrame([parse_line(line) for line in lines_test])\n",
    "\n",
    "# Slot labels\n",
    "slot_names = [\"[PAD]\", \"[EXTRA]\"]\n",
    "slot_names += Path(\"vocab.slot\").read_text().strip().splitlines()\n",
    "slot_map = {}\n",
    "for label in slot_names:\n",
    "    slot_map[label] = len(slot_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_label</th>\n",
       "      <th>words</th>\n",
       "      <th>word_labels</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>Add Don and Sherri to my Meditate to Sounds of...</td>\n",
       "      <td>O B-entity_name I-entity_name I-entity_name O ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>put United Abominations onto my rare groove pl...</td>\n",
       "      <td>O B-entity_name I-entity_name O B-playlist_own...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add the tune by misato watanabe to the Trapeo ...</td>\n",
       "      <td>O O B-music_item O B-artist I-artist O O B-pla...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add this artist to my this is miguel bosé play...</td>\n",
       "      <td>O O B-music_item O B-playlist_owner B-playlist...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add heresy and the hotel choir to the evening ...</td>\n",
       "      <td>O B-entity_name I-entity_name I-entity_name I-...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13079</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>find a Consolidated Theatres showing The Good ...</td>\n",
       "      <td>O O B-location_name I-location_name O B-movie_...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>where can i see animated movies in the neighbo...</td>\n",
       "      <td>O O O O B-movie_type I-movie_type B-spatial_re...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13081</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>Showtimes for animated movies in the area .</td>\n",
       "      <td>O O B-movie_type I-movie_type B-spatial_relati...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13082</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>Which animated movies are playing at Megaplex ...</td>\n",
       "      <td>O B-movie_type I-movie_type O O O B-location_n...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13083</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>What movie schedules start at sunset ?</td>\n",
       "      <td>O B-object_type I-object_type O O B-timeRange O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13084 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               intent_label  \\\n",
       "0             AddToPlaylist   \n",
       "1             AddToPlaylist   \n",
       "2             AddToPlaylist   \n",
       "3             AddToPlaylist   \n",
       "4             AddToPlaylist   \n",
       "...                     ...   \n",
       "13079  SearchScreeningEvent   \n",
       "13080  SearchScreeningEvent   \n",
       "13081  SearchScreeningEvent   \n",
       "13082  SearchScreeningEvent   \n",
       "13083  SearchScreeningEvent   \n",
       "\n",
       "                                                   words  \\\n",
       "0      Add Don and Sherri to my Meditate to Sounds of...   \n",
       "1      put United Abominations onto my rare groove pl...   \n",
       "2      add the tune by misato watanabe to the Trapeo ...   \n",
       "3      add this artist to my this is miguel bosé play...   \n",
       "4      add heresy and the hotel choir to the evening ...   \n",
       "...                                                  ...   \n",
       "13079  find a Consolidated Theatres showing The Good ...   \n",
       "13080  where can i see animated movies in the neighbo...   \n",
       "13081        Showtimes for animated movies in the area .   \n",
       "13082  Which animated movies are playing at Megaplex ...   \n",
       "13083             What movie schedules start at sunset ?   \n",
       "\n",
       "                                             word_labels  length  \n",
       "0      O B-entity_name I-entity_name I-entity_name O ...      12  \n",
       "1      O B-entity_name I-entity_name O B-playlist_own...       8  \n",
       "2      O O B-music_item O B-artist I-artist O O B-pla...      10  \n",
       "3      O O B-music_item O B-playlist_owner B-playlist...      10  \n",
       "4      O B-entity_name I-entity_name I-entity_name I-...      11  \n",
       "...                                                  ...     ...  \n",
       "13079  O O B-location_name I-location_name O B-movie_...      10  \n",
       "13080  O O O O B-movie_type I-movie_type B-spatial_re...       9  \n",
       "13081  O O B-movie_type I-movie_type B-spatial_relati...       8  \n",
       "13082  O B-movie_type I-movie_type O O O B-location_n...      11  \n",
       "13083    O B-object_type I-object_type O O B-timeRange O       7  \n",
       "\n",
       "[13084 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "SPECIAL_PIECE = \"▁\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_tokens_labels(\n",
    "    aligned_words, orig_to_new_index, label_tokens, sub_words_mapped, label_pad_token=\"[PAD]\"\n",
    "):\n",
    "    aligned_labels = [label_pad_token] * len(aligned_words)\n",
    "    for original_pos, new_pos in enumerate(orig_to_new_index):\n",
    "        aligned_labels[new_pos] = label_tokens[original_pos]\n",
    "    flat_tokens = []\n",
    "    flat_labels = []\n",
    "\n",
    "    # The first word of the subword token is assigned entity\n",
    "    # other tokens will be add PAD labels (we will mask it while training)\n",
    "    assert (len(aligned_words) == len(sub_words_mapped) == len(aligned_labels))\n",
    "    for (_align_word, _align_word, _align_label) in zip(\n",
    "        aligned_words, sub_words_mapped, aligned_labels\n",
    "    ):\n",
    "        temp_w = []\n",
    "        for _align_word in _align_word:\n",
    "            temp_w.append(_align_word)\n",
    "        temp_l = [label_pad_token] * len(temp_w)\n",
    "        temp_l[0] = _align_label\n",
    "        flat_tokens.extend(temp_w)\n",
    "        flat_labels.extend(temp_l)\n",
    "        \n",
    "    return flat_tokens, flat_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers.utils import fast_sp_alignment\n",
    "def tokenize_and_align_sentence_label(\n",
    "    sentence, word_tokens, label_tokens, label_pad_token\n",
    "):\n",
    "    subwords = tokenizer.tokenize(sentence)\n",
    "    orig_to_new_index, aligned_words, sub_words_mapped = fast_sp_alignment(\n",
    "            sentence, tokenizer, SPECIAL_PIECE\n",
    "        )\n",
    "    \n",
    "    flat_tokens, flat_labels = get_tokens_labels(aligned_words, orig_to_new_index, label_tokens, sub_words_mapped, label_pad_token\n",
    "    )\n",
    "    return flat_tokens, flat_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_max_length = 50  # 50 is enough for SNIPS\n",
    "\n",
    "\n",
    "def process_data_to_model_inputs(sentence, flat_labels, label_pad_token):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    result = {}\n",
    "    result[\"input_ids\"] = tokenizer.encode(\n",
    "        sentence, truncation=True, max_length=encoder_max_length\n",
    "    )\n",
    "    result[\"input_mask\"] = [1] * len(result[\"input_ids\"])\n",
    "    result[\"input_type_ids\"] = [0] * len(result[\"input_ids\"])\n",
    "    labels = [slot_map[token] for token in flat_labels]\n",
    "    labels = [slot_map[label_pad_token]] + labels + [slot_map[label_pad_token]]  # for [CLS] and [SEP]\n",
    "    label_mask = []\n",
    "    for token in flat_labels:\n",
    "        if token == [label_pad_token]:\n",
    "            label_mask.append(0)\n",
    "            continue\n",
    "        label_mask.append(1)\n",
    "    label_mask = [0] + label_mask + [0]  # for [CLS] and [SEP]\n",
    "    result[\"labels\"] = labels\n",
    "    result[\"label_mask\"] = label_mask\n",
    "    return result\n",
    "\n",
    "\n",
    "ignored_index = []\n",
    "def make_parse_fn(df):\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row[\"words\"]\n",
    "        labels = row[\"word_labels\"]\n",
    "        word_tokens = sentence.split()\n",
    "        label_tokens = labels.split()\n",
    "        if len(word_tokens) != len(label_tokens):\n",
    "            ignored_index.append(index)\n",
    "            continue\n",
    "        flat_tokens, flat_labels = tokenize_and_align_sentence_label(\n",
    "            sentence, word_tokens, label_tokens, label_pad_token=\"[PAD]\"\n",
    "        )\n",
    "        yield process_data_to_model_inputs(sentence, flat_labels, label_pad_token)\n",
    "    print(\"Ignored {} indexes\".format(len(ignored_index)))\n",
    "\n",
    "\n",
    "parse_fn = make_parse_fn(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Processed  10000 examples so far\n",
      "INFO:absl:Total individual observations/examples written is 13073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored 11 indexes\n"
     ]
    }
   ],
   "source": [
    "# use TFProcessor only if your data is in range of 10k - 20k maximum\n",
    "# otherwise use TFWriter\n",
    "from tf_transformers.data import TFProcessor\n",
    "\n",
    "tf_processor = TFProcessor()\n",
    "train_dataset = tf_processor.process(parse_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': RaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64),\n",
       " 'input_mask': RaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64),\n",
       " 'input_type_ids': RaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64),\n",
       " 'labels': RaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64),\n",
       " 'label_mask': RaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_transformers.data import separate_x_y\n",
    "def pad_ragged(dataset):\n",
    "    \"\"\"\n",
    "    Pad dataset of dict .\n",
    "\n",
    "    \"\"\"\n",
    "    dataset_padded = {}\n",
    "    for item, tensor in dataset.items():\n",
    "        if isinstance(tensor, tf.RaggedTensor):\n",
    "            dataset_padded[item] = tensor.to_tensor()\n",
    "        else:\n",
    "            dataset_padded[item] = tensor\n",
    "    return dataset_padded\n",
    "\n",
    "def auto_batch_for_training(tf_dataset, \n",
    "                            batch_size, \n",
    "                            x_keys = None,\n",
    "                            y_keys = None, \n",
    "                            shuffle=False, \n",
    "                            drop_remainder=False, \n",
    "                            shuffle_buffer_size=10000, \n",
    "                            prefetch_buffer_size=100):\n",
    "    element_spec = tf_dataset.element_spec\n",
    "    dataset = tf_dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    dataset = dataset.map(pad_ragged, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if x_keys and y_keys:\n",
    "        dataset = dataset.map(lambda x: separate_x_y(x, x_keys, y_keys),\n",
    "                                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(\n",
    "            shuffle_buffer_size, seed=None, reshuffle_each_iteration=True\n",
    "        )\n",
    "    dataset = dataset.prefetch(prefetch_buffer_size)\n",
    "    return dataset\n",
    "\n",
    "x_keys = ['input_ids', 'input_type_ids', 'input_mask']\n",
    "y_keys = ['labels', 'label_mask']\n",
    "train_dataset = auto_batch_for_training(train_dataset, batch_size=16, x_keys=x_keys, y_keys=y_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(16, 17), dtype=int32, numpy=\n",
      "array([[    2,  3547,   221,    17, 29533,    20,    51,  9488, 22443,\n",
      "           20,  2795,    16,  1444, 27063,     3,     0,     0],\n",
      "       [    2,   442,   181,    21,  1192, 15971,    18,  1204,    51,\n",
      "         2890, 12489, 27063,     3,     0,     0,     0,     0],\n",
      "       [    2,  3547,    14,  6768,    34,  2462,  6043, 29592,    20,\n",
      "           14,  5585,  3894, 27063,     3,     0,     0,     0],\n",
      "       [    2,  3547,    48,  1169,    20,    51,    48,    25,  8025,\n",
      "        22629, 27063,     3,     0,     0,     0,     0,     0],\n",
      "       [    2,  3547,   235,  4980,    17,    14,  1454,  4962,    20,\n",
      "           14,  2089,  5402, 27063,     3,     0,     0,     0],\n",
      "       [    2,  2247,  3547,   487,  8883,  3532,    20,    51, 27063,\n",
      "           48,    25, 14241,     3,     0,     0,     0,     0],\n",
      "       [    2,  3547,    40,   244,    20,    51,   968,   333,    55,\n",
      "        10070,   232,    58,  1329,   814,     3,     0,     0],\n",
      "       [    2,  3547,  7912,    27,    42,    20,    51,  5001,    16,\n",
      "         1484, 27063,     3,     0,     0,     0,     0,     0],\n",
      "       [    2,  3547,  1169,    20, 27063,  7269, 10968,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       [    2,  3547,    14,   932,  1206,  1204,    51,    13, 18949,\n",
      "        11614,    62, 27063,  2247,     9,     3,     0,     0],\n",
      "       [    2,   442,   226,   792,    19,    51,  3253,    58,   279,\n",
      "         1329, 27063,     9,     3,     0,     0,     0,     0],\n",
      "       [    2,  3547,    48,   244,    20,    14, 27063,   227,  8827,\n",
      "        10903,    68,     3,     0,     0,     0,     0,     0],\n",
      "       [    2,  3547,  2732,  6769,    34,  2438,   220,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       [    2,  3547,    55,  4099,  1324,   804, 14356, 10600,   916,\n",
      "           26, 13672,   445,    20,    51, 27063,  1169,     3],\n",
      "       [    2,  3547,    14,   204,  3004,    95,  1329,    20, 27063,\n",
      "          629,     3,     0,     0,     0,     0,     0,     0],\n",
      "       [    2,  3547,  1358,  1353,  2373,  4100,    20,    51,  9193,\n",
      "           58, 17258,   444, 27063,     3,     0,     0,     0]],\n",
      "      dtype=int32)>, 'input_mask': <tf.Tensor: shape=(16, 17), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]], dtype=int32)>, 'input_type_ids': <tf.Tensor: shape=(16, 17), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}, {'labels': <tf.Tensor: shape=(16, 17), dtype=int32, numpy=\n",
      "array([[ 0, 73, 11, 47, 47, 73, 27, 26,  0, 61, 61, 61, 61, 73,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 11, 47,  0,  0,  0, 73, 27, 26, 61, 73,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 73, 18, 73,  3,  0, 42, 73, 73, 26,  0, 73,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 73, 18, 73, 27, 26, 61, 61, 61, 73,  0,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 11,  0, 47, 47, 47, 47, 73, 73, 26, 61, 73,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 73,  3,  0, 42, 73, 27, 73, 26, 61, 61,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 73, 18, 73, 27, 73, 26, 61,  0, 61,  0, 61, 61,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 11, 47, 47, 73, 27, 26, 61, 61, 73,  0,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 18, 73, 73, 26, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 11, 47, 47, 73, 27, 26,  0, 61,  0, 73, 73,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 73, 18, 73, 27, 26,  0, 61, 61, 73,  0,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 73, 18, 73, 73, 73, 73, 26,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73, 26, 61, 73,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73,  3,  0, 42,  0,  0, 26, 61, 61, 61,  0, 73, 27, 73, 18,\n",
      "         0],\n",
      "       [ 0, 73, 73, 73, 11, 47, 47, 73, 73, 26,  0,  0,  0,  0,  0,  0,\n",
      "         0],\n",
      "       [ 0, 73,  3, 42,  0, 42, 73, 27, 26,  0, 61,  0, 73,  0,  0,  0,\n",
      "         0]], dtype=int32)>, 'label_mask': <tf.Tensor: shape=(16, 17), dtype=int32, numpy=\n",
      "array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], dtype=int32)>})\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataset:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Initialized Variables\n"
     ]
    }
   ],
   "source": [
    "#### Load Albert Model\n",
    "\n",
    "from tf_transformers.models import AlbertModel\n",
    "model_layer, model, config = AlbertModel(model_name='albert_base_v2', \n",
    "                   is_training=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers.core import LegacyModel, LegacyLayer\n",
    "\n",
    "\n",
    "class Token_Classification(LegacyLayer):\n",
    "    def __init__(self, model, token_vocab_size, use_all_layers=False, activation=\"tanh\", **kwargs):\n",
    "        super(Token_Classification, self).__init__(**kwargs)\n",
    "        self.model = model\n",
    "        if isinstance(model, LegacyModel):\n",
    "            self.model_config = model.model_config\n",
    "        elif isinstance(model, tf.keras.layers.Layer):\n",
    "            self.model_config = model._config_dict\n",
    "        self.use_all_layers = use_all_layers\n",
    "        self.logits_layer = tf.keras.layers.Dense(\n",
    "            token_vocab_size,\n",
    "            activation=activation,\n",
    "            use_bias=True,\n",
    "            kernel_initializer=\"glorot_uniform\",\n",
    "            bias_initializer=\"zeros\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        result = self.model(inputs)\n",
    "        token_logits = []\n",
    "        if self.use_all_layers:\n",
    "            # each layer token embeddings\n",
    "            for token_embeddings in result[\"all_layer_token_embeddings\"]:\n",
    "                outputs = self.logits_layer(token_embeddings)\n",
    "                token_logits.append(outputs)\n",
    "            return {'token_logits': token_logits}            \n",
    "\n",
    "        else:\n",
    "            # last layer token embeddings\n",
    "            token_embeddings = result[\"token_embeddings\"]\n",
    "            outputs = self.logits_layer(token_embeddings)\n",
    "            return {\n",
    "                    \"token_logits\": outputs\n",
    "            }\n",
    "        \n",
    "    def get_model(self):\n",
    "        layer_output = self(self.model.input)\n",
    "        model = LegacyModel(inputs=self.model.input, outputs=layer_output, name='span_selection')\n",
    "        model.model_config = self.model_config\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "token_classification_layer = Token_Classification(model=model,\n",
    "                                      token_vocab_size=len(slot_map),\n",
    "                                      use_all_layers=True, \n",
    "                                      is_training=True)\n",
    "token_classification_model = token_classification_layer.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = token_classification_model(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_logits': [<tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[-0.6589864 , -0.7563687 ,  0.98634696, ...,  0.650301  ,\n",
       "            0.6654792 , -0.90308124],\n",
       "          [ 0.19518195, -0.98253757, -0.6353485 , ...,  0.94649124,\n",
       "           -0.19243817,  0.84831876],\n",
       "          [ 0.49345627, -0.5446298 ,  0.758992  , ...,  0.31135795,\n",
       "            0.1970949 , -0.8132535 ],\n",
       "          ...,\n",
       "          [ 0.6537937 , -0.29818448,  0.9170768 , ...,  0.05026689,\n",
       "           -0.8158943 ,  0.3864477 ],\n",
       "          [ 0.9923766 , -0.2081895 , -0.47042075, ...,  0.77227235,\n",
       "            0.9294651 ,  0.51044583],\n",
       "          [ 0.905505  , -0.95786756,  0.91853935, ...,  0.52693677,\n",
       "           -0.2729776 ,  0.20590636]],\n",
       "  \n",
       "         [[-0.70921683, -0.78513074,  0.9884197 , ...,  0.70700794,\n",
       "            0.671792  , -0.9010645 ],\n",
       "          [ 0.360376  , -0.9713132 ,  0.586849  , ...,  0.9923516 ,\n",
       "            0.80661714,  0.32555136],\n",
       "          [ 0.78514266, -0.9592638 ,  0.9210562 , ..., -0.88119113,\n",
       "           -0.30244973, -0.58588487],\n",
       "          ...,\n",
       "          [ 0.9793697 , -0.85582584,  0.98683447, ...,  0.7857207 ,\n",
       "           -0.47652707,  0.7188902 ],\n",
       "          [ 0.99048305, -0.2844322 , -0.390861  , ...,  0.8131181 ,\n",
       "            0.9278883 ,  0.5250988 ],\n",
       "          [ 0.88178664, -0.9632023 ,  0.93156487, ...,  0.59435993,\n",
       "           -0.27546015,  0.21804838]],\n",
       "  \n",
       "         [[-0.6846996 , -0.7274612 ,  0.98983145, ...,  0.68498373,\n",
       "            0.6018886 , -0.91199636],\n",
       "          [ 0.13373579, -0.9804196 , -0.54397815, ...,  0.9519007 ,\n",
       "           -0.28387317,  0.83785045],\n",
       "          [ 0.72688985, -0.91492957, -0.16378897, ..., -0.63892305,\n",
       "           -0.45900238, -0.3810977 ],\n",
       "          ...,\n",
       "          [ 0.9816179 , -0.8145397 ,  0.98814034, ...,  0.7634708 ,\n",
       "           -0.5545508 ,  0.6856476 ],\n",
       "          [ 0.99146307, -0.15173778, -0.3442636 , ...,  0.7912073 ,\n",
       "            0.91170275,  0.47527164],\n",
       "          [ 0.8959984 , -0.9523617 ,  0.93739176, ...,  0.5611688 ,\n",
       "           -0.37416798,  0.15800256]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-0.6979652 , -0.77956575,  0.9894037 , ...,  0.6456686 ,\n",
       "            0.66277146, -0.9005427 ],\n",
       "          [ 0.12691449, -0.9844409 , -0.5617111 , ...,  0.9444362 ,\n",
       "           -0.18408248,  0.8519047 ],\n",
       "          [ 0.92443794, -0.89475274,  0.55512834, ...,  0.63656723,\n",
       "           -0.45745054, -0.70152384],\n",
       "          ...,\n",
       "          [ 0.7331296 , -0.8131495 ,  0.74038154, ...,  0.7259484 ,\n",
       "           -0.7890057 ,  0.42184347],\n",
       "          [ 0.94765186, -0.8512012 , -0.5217564 , ...,  0.03872186,\n",
       "            0.7752302 , -0.8698271 ],\n",
       "          [-0.29050043, -0.8968008 ,  0.6504298 , ..., -0.290459  ,\n",
       "           -0.7540767 , -0.14835015]],\n",
       "  \n",
       "         [[-0.66475165, -0.73389226,  0.9885934 , ...,  0.687703  ,\n",
       "            0.6802359 , -0.8924868 ],\n",
       "          [ 0.18377267, -0.9809726 , -0.58266616, ...,  0.9527512 ,\n",
       "           -0.18137173,  0.86508936],\n",
       "          [ 0.74547803, -0.91931784, -0.21595083, ..., -0.6329295 ,\n",
       "           -0.35496208, -0.28237176],\n",
       "          ...,\n",
       "          [ 0.9832517 , -0.8196036 ,  0.98685384, ...,  0.77477556,\n",
       "           -0.47044966,  0.73635095],\n",
       "          [ 0.9921807 , -0.15280128, -0.4031272 , ...,  0.799344  ,\n",
       "            0.9309626 ,  0.5489717 ],\n",
       "          [ 0.9029617 , -0.95364827,  0.93126386, ...,  0.576035  ,\n",
       "           -0.26457852,  0.25516394]],\n",
       "  \n",
       "         [[-0.6745485 , -0.7782732 ,  0.9908135 , ...,  0.6541808 ,\n",
       "            0.6409635 , -0.9119504 ],\n",
       "          [ 0.16745073, -0.9842911 , -0.5129616 , ...,  0.947582  ,\n",
       "           -0.22218041,  0.8341001 ],\n",
       "          [ 0.800163  , -0.9918151 ,  0.28183305, ...,  0.6849319 ,\n",
       "            0.7847492 , -0.7853867 ],\n",
       "          ...,\n",
       "          [ 0.98298764, -0.8506445 ,  0.9892184 , ...,  0.7438503 ,\n",
       "           -0.510661  ,  0.6833641 ],\n",
       "          [ 0.99225277, -0.2555633 , -0.3009182 , ...,  0.77365595,\n",
       "            0.9237634 ,  0.47639495],\n",
       "          [ 0.90361553, -0.96272624,  0.9438942 , ...,  0.53286487,\n",
       "           -0.31356788,  0.14804919]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[-0.6195761 , -0.84707695,  0.92945814, ...,  0.52524465,\n",
       "            0.5182931 , -0.8307662 ],\n",
       "          [ 0.76118743, -0.9898997 , -0.62157714, ...,  0.78945345,\n",
       "           -0.25152174,  0.86631376],\n",
       "          [ 0.90244657, -0.6656645 ,  0.5591955 , ...,  0.35590994,\n",
       "            0.15091908, -0.85997266],\n",
       "          ...,\n",
       "          [ 0.94648516, -0.57328457,  0.8006663 , ..., -0.46005765,\n",
       "           -0.75255907,  0.52711546],\n",
       "          [ 0.99462134, -0.6802991 , -0.3401632 , ...,  0.46453446,\n",
       "            0.8883187 ,  0.64183396],\n",
       "          [ 0.9802107 , -0.9795139 ,  0.8609326 , ...,  0.36143494,\n",
       "           -0.17610402,  0.54219836]],\n",
       "  \n",
       "         [[-0.7161565 , -0.88373774,  0.951888  , ...,  0.6396612 ,\n",
       "            0.5227923 , -0.81862485],\n",
       "          [ 0.74623317, -0.9845371 ,  0.6653152 , ...,  0.96579957,\n",
       "            0.7608336 ,  0.58630025],\n",
       "          [ 0.959623  , -0.97810143,  0.91812986, ..., -0.92073053,\n",
       "           -0.48760837, -0.48637128],\n",
       "          ...,\n",
       "          [ 0.9942169 , -0.970347  ,  0.96447253, ...,  0.58876264,\n",
       "           -0.5702565 ,  0.821234  ],\n",
       "          [ 0.99176586, -0.77060175, -0.12319294, ...,  0.6020031 ,\n",
       "            0.8789289 ,  0.66491485],\n",
       "          [ 0.9689906 , -0.98501724,  0.9053228 , ...,  0.5028169 ,\n",
       "           -0.20392168,  0.5664457 ]],\n",
       "  \n",
       "         [[-0.6782043 , -0.8084387 ,  0.95810676, ...,  0.6206071 ,\n",
       "            0.39039537, -0.8627262 ],\n",
       "          [ 0.69816494, -0.98744607, -0.44097194, ...,  0.8309386 ,\n",
       "           -0.38752317,  0.8493839 ],\n",
       "          [ 0.9372722 , -0.93319124, -0.00760999, ..., -0.7179439 ,\n",
       "           -0.57084924, -0.5468775 ],\n",
       "          ...,\n",
       "          [ 0.9952616 , -0.94795716,  0.9684365 , ...,  0.54077154,\n",
       "           -0.6623709 ,  0.7624372 ],\n",
       "          [ 0.99319315, -0.62794983, -0.07932537, ...,  0.55345106,\n",
       "            0.8435156 ,  0.570031  ],\n",
       "          [ 0.97552484, -0.97488105,  0.912362  , ...,  0.4526045 ,\n",
       "           -0.33987635,  0.4540907 ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-0.68425715, -0.87722296,  0.9541178 , ...,  0.52653736,\n",
       "            0.5247543 , -0.81955224],\n",
       "          [ 0.69843936, -0.99207103, -0.4873906 , ...,  0.78150344,\n",
       "           -0.21788661,  0.87958986],\n",
       "          [ 0.9835793 , -0.92400324,  0.551906  , ...,  0.48522395,\n",
       "           -0.65425634, -0.6734708 ],\n",
       "          ...,\n",
       "          [ 0.9423465 , -0.9386122 ,  0.3406364 , ...,  0.40729845,\n",
       "           -0.80371046,  0.38261384],\n",
       "          [ 0.96894073, -0.9122388 , -0.3906312 , ..., -0.294868  ,\n",
       "            0.7191702 , -0.8417044 ],\n",
       "          [ 0.66890997, -0.9366731 ,  0.6681099 , ..., -0.5053663 ,\n",
       "           -0.60638803,  0.31287837]],\n",
       "  \n",
       "         [[-0.61494577, -0.82521117,  0.94440645, ...,  0.58339083,\n",
       "            0.56886375, -0.7878092 ],\n",
       "          [ 0.7604214 , -0.98836243, -0.52605444, ...,  0.8191436 ,\n",
       "           -0.22796041,  0.8959344 ],\n",
       "          [ 0.9504655 , -0.94249564, -0.12249526, ..., -0.7362566 ,\n",
       "           -0.425752  , -0.37682375],\n",
       "          ...,\n",
       "          [ 0.99624807, -0.95282876,  0.95873505, ...,  0.5347456 ,\n",
       "           -0.5469685 ,  0.83904105],\n",
       "          [ 0.9946311 , -0.635517  , -0.23610948, ...,  0.53881496,\n",
       "            0.89397305,  0.6931792 ],\n",
       "          [ 0.98021835, -0.9769552 ,  0.89064103, ...,  0.44326434,\n",
       "           -0.15316029,  0.6081298 ]],\n",
       "  \n",
       "         [[-0.67084557, -0.87007475,  0.96500325, ...,  0.5527133 ,\n",
       "            0.4644357 , -0.85813296],\n",
       "          [ 0.72438633, -0.99189985, -0.3977422 , ...,  0.80979854,\n",
       "           -0.30496094,  0.8415292 ],\n",
       "          [ 0.9193603 , -0.9949565 ,  0.27640197, ...,  0.497808  ,\n",
       "            0.6446918 , -0.8414525 ],\n",
       "          ...,\n",
       "          [ 0.9957628 , -0.966832  ,  0.97156835, ...,  0.4752686 ,\n",
       "           -0.6124709 ,  0.7687767 ],\n",
       "          [ 0.9941271 , -0.73286384,  0.00684274, ...,  0.4898809 ,\n",
       "            0.8712735 ,  0.5821619 ],\n",
       "          [ 0.97853976, -0.9840864 ,  0.9267785 , ...,  0.3963787 ,\n",
       "           -0.2622243 ,  0.44961208]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[-0.539892  , -0.8619417 ,  0.74170893, ...,  0.5258582 ,\n",
       "            0.3048527 , -0.7618046 ],\n",
       "          [ 0.9254416 , -0.9919001 , -0.52281064, ...,  0.58673537,\n",
       "           -0.33869174,  0.8835171 ],\n",
       "          [ 0.97286147, -0.6790355 ,  0.3051625 , ...,  0.5274585 ,\n",
       "            0.07860822, -0.88445884],\n",
       "          ...,\n",
       "          [ 0.98611236, -0.69716334,  0.66179544, ..., -0.57047325,\n",
       "           -0.68032926,  0.60536   ],\n",
       "          [ 0.9946805 , -0.8259332 , -0.15499155, ...,  0.29558533,\n",
       "            0.778699  ,  0.67862284],\n",
       "          [ 0.9921678 , -0.9812899 ,  0.7892642 , ...,  0.42788988,\n",
       "           -0.1136211 ,  0.68961227]],\n",
       "  \n",
       "         [[-0.6716365 , -0.91024655,  0.8495412 , ...,  0.66494274,\n",
       "            0.3035813 , -0.7328486 ],\n",
       "          [ 0.9120726 , -0.98811924,  0.73347116, ...,  0.9299319 ,\n",
       "            0.6513107 ,  0.7272708 ],\n",
       "          [ 0.9865059 , -0.98438543,  0.9044422 , ..., -0.90543014,\n",
       "           -0.5944895 , -0.3800485 ],\n",
       "          ...,\n",
       "          [ 0.9968911 , -0.9869363 ,  0.9294793 , ...,  0.5505757 ,\n",
       "           -0.60220504,  0.834975  ],\n",
       "          [ 0.99078345, -0.90124875,  0.20497017, ...,  0.4914484 ,\n",
       "            0.75507396,  0.71098626],\n",
       "          [ 0.98625684, -0.9887758 ,  0.8826679 , ...,  0.58916056,\n",
       "           -0.15468237,  0.72291255]],\n",
       "  \n",
       "         [[-0.6333163 , -0.8168587 ,  0.86229306, ...,  0.6643506 ,\n",
       "            0.1208038 , -0.82215434],\n",
       "          [ 0.8940946 , -0.9891214 , -0.230135  , ...,  0.6999042 ,\n",
       "           -0.47832572,  0.86568725],\n",
       "          [ 0.9774228 , -0.9237152 ,  0.10809772, ..., -0.70215964,\n",
       "           -0.64505637, -0.62647307],\n",
       "          ...,\n",
       "          [ 0.9975774 , -0.96933013,  0.93472826, ...,  0.51065236,\n",
       "           -0.68954057,  0.74228376],\n",
       "          [ 0.992748  , -0.78619057,  0.20965105, ...,  0.45447075,\n",
       "            0.6886652 ,  0.57637507],\n",
       "          [ 0.9897729 , -0.97586673,  0.88469553, ...,  0.56430686,\n",
       "           -0.29185548,  0.5874894 ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-0.6251521 , -0.90463966,  0.8481097 , ...,  0.556963  ,\n",
       "            0.3373266 , -0.7349593 ],\n",
       "          [ 0.8941404 , -0.99437964, -0.30601886, ...,  0.59279656,\n",
       "           -0.26957464,  0.90447706],\n",
       "          [ 0.99390376, -0.94157904,  0.5963185 , ...,  0.48591143,\n",
       "           -0.7379886 , -0.5723955 ],\n",
       "          ...,\n",
       "          [ 0.97668487, -0.96474314,  0.04388491, ...,  0.28540134,\n",
       "           -0.80234647,  0.25466663],\n",
       "          [ 0.97804403, -0.94441193, -0.36567912, ..., -0.24638167,\n",
       "            0.6208173 , -0.80646825],\n",
       "          [ 0.93104625, -0.9499758 ,  0.7007477 , ..., -0.4738414 ,\n",
       "           -0.46884552,  0.6264914 ]],\n",
       "  \n",
       "         [[-0.50541836, -0.84514415,  0.79195666, ...,  0.5722371 ,\n",
       "            0.39703345, -0.6658987 ],\n",
       "          [ 0.9295721 , -0.9906949 , -0.38672104, ...,  0.6373811 ,\n",
       "           -0.3039995 ,  0.91923624],\n",
       "          [ 0.9849309 , -0.9402258 , -0.06721146, ..., -0.75728375,\n",
       "           -0.5159837 , -0.3992642 ],\n",
       "          ...,\n",
       "          [ 0.9982418 , -0.97449565,  0.8996453 , ...,  0.43972442,\n",
       "           -0.5748384 ,  0.8573105 ],\n",
       "          [ 0.994928  , -0.79932946, -0.03996144, ...,  0.36841574,\n",
       "            0.7905652 ,  0.74324155],\n",
       "          [ 0.99256843, -0.9790092 ,  0.83718   , ...,  0.49330896,\n",
       "           -0.08237668,  0.7613571 ]],\n",
       "  \n",
       "         [[-0.64121205, -0.8907255 ,  0.88833517, ...,  0.58509123,\n",
       "            0.21276881, -0.8135345 ],\n",
       "          [ 0.90311515, -0.9941428 , -0.1847492 , ...,  0.65891063,\n",
       "           -0.39154378,  0.8475318 ],\n",
       "          [ 0.9557079 , -0.99450344,  0.282039  , ...,  0.46311173,\n",
       "            0.37718257, -0.85781366],\n",
       "          ...,\n",
       "          [ 0.9977793 , -0.98371553,  0.9382895 , ...,  0.40531448,\n",
       "           -0.6465459 ,  0.75451386],\n",
       "          [ 0.9936994 , -0.8686533 ,  0.2990403 , ...,  0.35500136,\n",
       "            0.7389941 ,  0.59305364],\n",
       "          [ 0.99097085, -0.9870009 ,  0.9025732 , ...,  0.49292207,\n",
       "           -0.22597478,  0.57920617]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[-0.39338797, -0.84002614,  0.43059242, ...,  0.6153763 ,\n",
       "            0.11132575, -0.7133112 ],\n",
       "          [ 0.9686526 , -0.9917374 , -0.35832044, ...,  0.4917543 ,\n",
       "           -0.43391767,  0.8904158 ],\n",
       "          [ 0.98715883, -0.64101917,  0.10509256, ...,  0.6978169 ,\n",
       "           -0.01363139, -0.896211  ],\n",
       "          ...,\n",
       "          [ 0.9939615 , -0.7486266 ,  0.5527042 , ..., -0.48266384,\n",
       "           -0.6168266 ,  0.6327469 ],\n",
       "          [ 0.99386775, -0.8688817 ,  0.04062023, ...,  0.33219373,\n",
       "            0.55704725,  0.6428483 ],\n",
       "          [ 0.9947097 , -0.9758941 ,  0.7214987 , ...,  0.5813436 ,\n",
       "           -0.11351467,  0.716714  ]],\n",
       "  \n",
       "         [[-0.54416597, -0.90879494,  0.682076  , ...,  0.739616  ,\n",
       "            0.11000297, -0.66608846],\n",
       "          [ 0.9657185 , -0.98859817,  0.79393154, ...,  0.91782033,\n",
       "            0.4901618 ,  0.7843659 ],\n",
       "          [ 0.9925648 , -0.9856477 ,  0.8880943 , ..., -0.84257865,\n",
       "           -0.64862674, -0.30697268],\n",
       "          ...,\n",
       "          [ 0.99723977, -0.98966867,  0.89234227, ...,  0.64806265,\n",
       "           -0.60319453,  0.7870161 ],\n",
       "          [ 0.9889968 , -0.9378971 ,  0.47492987, ...,  0.5201038 ,\n",
       "            0.5275213 ,  0.6872801 ],\n",
       "          [ 0.9907428 , -0.98788196,  0.86871433, ...,  0.7152896 ,\n",
       "           -0.14826052,  0.7610877 ]],\n",
       "  \n",
       "         [[-0.528366  , -0.7851403 ,  0.6952063 , ...,  0.7566043 ,\n",
       "           -0.10151328, -0.79166234],\n",
       "          [ 0.9535588 , -0.98830926,  0.03657741, ...,  0.6652664 ,\n",
       "           -0.5614636 ,  0.8774656 ],\n",
       "          [ 0.98837364, -0.90002257,  0.20042144, ..., -0.61889505,\n",
       "           -0.69241196, -0.65437216],\n",
       "          ...,\n",
       "          [ 0.99784076, -0.96943474,  0.89422125, ...,  0.6331993 ,\n",
       "           -0.6866073 ,  0.63805544],\n",
       "          [ 0.99136007, -0.8329789 ,  0.44531548, ...,  0.51888907,\n",
       "            0.4180125 ,  0.51243377],\n",
       "          [ 0.99312514, -0.96818674,  0.86047095, ...,  0.72401106,\n",
       "           -0.2732735 ,  0.6063944 ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-0.49632862, -0.9066569 ,  0.6695094 , ...,  0.67783463,\n",
       "            0.18207854, -0.66393656],\n",
       "          [ 0.95250237, -0.99492526, -0.05390064, ...,  0.5379617 ,\n",
       "           -0.3365244 ,  0.9181874 ],\n",
       "          [ 0.9963589 , -0.95316947,  0.6873451 , ...,  0.59611946,\n",
       "           -0.76857966, -0.41961107],\n",
       "          ...,\n",
       "          [ 0.9836711 , -0.97115046, -0.02167904, ...,  0.38520166,\n",
       "           -0.7970385 ,  0.07379401],\n",
       "          [ 0.9835212 , -0.96208704, -0.40717787, ...,  0.03531774,\n",
       "            0.47125393, -0.76611334],\n",
       "          [ 0.979302  , -0.9534144 ,  0.74171084, ..., -0.2858555 ,\n",
       "           -0.3853079 ,  0.7810208 ]],\n",
       "  \n",
       "         [[-0.31018466, -0.83514947,  0.5060975 , ...,  0.6364071 ,\n",
       "            0.23323539, -0.557771  ],\n",
       "          [ 0.97277504, -0.9910356 , -0.19770712, ...,  0.54247594,\n",
       "           -0.39739138,  0.9305412 ],\n",
       "          [ 0.99317074, -0.9283755 , -0.03418865, ..., -0.72654074,\n",
       "           -0.6012106 , -0.3817319 ],\n",
       "          ...,\n",
       "          [ 0.9984707 , -0.97714996,  0.8137628 , ...,  0.50945073,\n",
       "           -0.5810011 ,  0.8234697 ],\n",
       "          [ 0.9944053 , -0.85577834,  0.14123039, ...,  0.36298135,\n",
       "            0.5792393 ,  0.7327314 ],\n",
       "          [ 0.99527884, -0.97408205,  0.7809137 , ...,  0.6115399 ,\n",
       "           -0.0733589 ,  0.8037542 ]],\n",
       "  \n",
       "         [[-0.5622858 , -0.8831261 ,  0.75040823, ...,  0.69470894,\n",
       "           -0.00601278, -0.7877881 ],\n",
       "          [ 0.9550515 , -0.9945424 ,  0.08015446, ...,  0.6181849 ,\n",
       "           -0.47361553,  0.84176975],\n",
       "          [ 0.9693947 , -0.99176306,  0.32358786, ...,  0.5552382 ,\n",
       "            0.04490218, -0.856406  ],\n",
       "          ...,\n",
       "          [ 0.99787253, -0.98582155,  0.8928469 , ...,  0.5228791 ,\n",
       "           -0.64745367,  0.6473336 ],\n",
       "          [ 0.992042  , -0.9087157 ,  0.5112313 , ...,  0.41782054,\n",
       "            0.49224153,  0.5150126 ],\n",
       "          [ 0.99350524, -0.9847435 ,  0.8757537 , ...,  0.66039985,\n",
       "           -0.22420767,  0.57915205]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[-1.85387239e-01, -7.82488823e-01,  1.65842637e-01, ...,\n",
       "            7.27422476e-01,  9.08677559e-03, -6.80232048e-01],\n",
       "          [ 9.81543720e-01, -9.89677250e-01, -1.49435028e-01, ...,\n",
       "            5.08421779e-01, -5.15067101e-01,  8.82824004e-01],\n",
       "          [ 9.90612209e-01, -5.67870796e-01,  2.42460500e-02, ...,\n",
       "            8.10275376e-01, -1.05919287e-01, -8.96732628e-01],\n",
       "          ...,\n",
       "          [ 9.96113122e-01, -7.62776613e-01,  4.85254377e-01, ...,\n",
       "           -2.58208007e-01, -5.63965678e-01,  6.26760304e-01],\n",
       "          [ 9.92464721e-01, -8.75404954e-01,  2.14457914e-01, ...,\n",
       "            4.81485039e-01,  2.33614177e-01,  5.41637719e-01],\n",
       "          [ 9.94817197e-01, -9.64332700e-01,  6.74045682e-01, ...,\n",
       "            7.08562553e-01, -1.43871307e-01,  6.71058059e-01]],\n",
       "  \n",
       "         [[-3.12534660e-01, -8.85336399e-01,  5.17967582e-01, ...,\n",
       "            8.15923929e-01,  1.62308551e-02, -6.15166664e-01],\n",
       "          [ 9.82597828e-01, -9.86931324e-01,  8.44784915e-01, ...,\n",
       "            9.26408052e-01,  3.09586614e-01,  7.92332530e-01],\n",
       "          [ 9.94122803e-01, -9.83204007e-01,  8.76378357e-01, ...,\n",
       "           -7.04306722e-01, -6.68287814e-01, -2.70802051e-01],\n",
       "          ...,\n",
       "          [ 9.96654212e-01, -9.87826228e-01,  8.58262777e-01, ...,\n",
       "            7.63300121e-01, -5.88469863e-01,  6.69067025e-01],\n",
       "          [ 9.87140596e-01, -9.46904540e-01,  6.43824399e-01, ...,\n",
       "            6.17876112e-01,  2.31761560e-01,  6.02091253e-01],\n",
       "          [ 9.91740346e-01, -9.84085977e-01,  8.63203824e-01, ...,\n",
       "            8.02874804e-01, -1.60454929e-01,  7.34308600e-01]],\n",
       "  \n",
       "         [[-3.50661606e-01, -7.11582065e-01,  5.27337074e-01, ...,\n",
       "            8.41952920e-01, -2.16540605e-01, -7.58748174e-01],\n",
       "          [ 9.73459005e-01, -9.84949827e-01,  2.87984014e-01, ...,\n",
       "            7.08298743e-01, -6.28873169e-01,  8.79566610e-01],\n",
       "          [ 9.92361307e-01, -8.66932333e-01,  2.88648397e-01, ...,\n",
       "           -4.69174832e-01, -7.13403523e-01, -6.44736946e-01],\n",
       "          ...,\n",
       "          [ 9.97276604e-01, -9.58275735e-01,  8.52839351e-01, ...,\n",
       "            7.68932223e-01, -6.75524890e-01,  4.49689299e-01],\n",
       "          [ 9.89555418e-01, -8.36857498e-01,  6.00936949e-01, ...,\n",
       "            6.48966134e-01,  7.91761354e-02,  3.98191601e-01],\n",
       "          [ 9.93680954e-01, -9.52763855e-01,  8.41955960e-01, ...,\n",
       "            8.30906391e-01, -2.76017994e-01,  5.59007585e-01]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-2.92352468e-01, -8.91657174e-01,  4.98010844e-01, ...,\n",
       "            8.00622642e-01,  1.23538420e-01, -5.99667370e-01],\n",
       "          [ 9.71531868e-01, -9.94357765e-01,  2.05455080e-01, ...,\n",
       "            5.97193599e-01, -3.98965329e-01,  9.20020759e-01],\n",
       "          [ 9.96873558e-01, -9.59499896e-01,  7.79075205e-01, ...,\n",
       "            7.18171954e-01, -7.72726357e-01, -2.49307260e-01],\n",
       "          ...,\n",
       "          [ 9.83835161e-01, -9.71243799e-01,  6.83413967e-02, ...,\n",
       "            5.70359647e-01, -7.89139211e-01, -1.08785376e-01],\n",
       "          [ 9.87058461e-01, -9.71704662e-01, -4.52765554e-01, ...,\n",
       "            3.95001531e-01,  2.79546916e-01, -7.20722198e-01],\n",
       "          [ 9.90854681e-01, -9.51735675e-01,  7.83520281e-01, ...,\n",
       "            7.14265974e-03, -3.43313187e-01,  8.49422514e-01]],\n",
       "  \n",
       "         [[-4.49692421e-02, -8.04499626e-01,  2.11235479e-01, ...,\n",
       "            7.29076743e-01,  1.46284774e-01, -4.68023121e-01],\n",
       "          [ 9.85237658e-01, -9.89825130e-01,  5.12599945e-05, ...,\n",
       "            5.53386688e-01, -4.82578933e-01,  9.30456102e-01],\n",
       "          [ 9.95748460e-01, -9.13399637e-01, -4.20570286e-04, ...,\n",
       "           -6.46669686e-01, -6.56158328e-01, -3.34758878e-01],\n",
       "          ...,\n",
       "          [ 9.98008132e-01, -9.72519457e-01,  7.13596046e-01, ...,\n",
       "            6.37889683e-01, -5.74314356e-01,  7.35583067e-01],\n",
       "          [ 9.93417442e-01, -8.76121879e-01,  2.78798640e-01, ...,\n",
       "            4.64783639e-01,  2.73510635e-01,  6.76523983e-01],\n",
       "          [ 9.95685935e-01, -9.64927375e-01,  7.30527699e-01, ...,\n",
       "            7.11425662e-01, -9.02242213e-02,  7.92031825e-01]],\n",
       "  \n",
       "         [[-4.25334394e-01, -8.52105796e-01,  6.04576409e-01, ...,\n",
       "            8.06357443e-01, -1.14942968e-01, -7.72627652e-01],\n",
       "          [ 9.71592665e-01, -9.93633747e-01,  3.35966557e-01, ...,\n",
       "            6.67162597e-01, -5.41183114e-01,  8.17213178e-01],\n",
       "          [ 9.75005448e-01, -9.85486209e-01,  3.98232758e-01, ...,\n",
       "            6.82159841e-01, -2.27240294e-01, -8.44590664e-01],\n",
       "          ...,\n",
       "          [ 9.97007668e-01, -9.82348382e-01,  8.43023777e-01, ...,\n",
       "            6.84705973e-01, -6.32718205e-01,  4.27796572e-01],\n",
       "          [ 9.89350319e-01, -9.17884946e-01,  6.45724952e-01, ...,\n",
       "            5.75330198e-01,  1.69019356e-01,  3.51771981e-01],\n",
       "          [ 9.93300498e-01, -9.78927314e-01,  8.53258371e-01, ...,\n",
       "            7.84988463e-01, -2.33441174e-01,  4.88929629e-01]]],\n",
       "        dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[ 0.03577165, -0.6793596 ,  0.03910394, ...,  0.8206467 ,\n",
       "            0.01362919, -0.6523407 ],\n",
       "          [ 0.9849114 , -0.98482764,  0.07232941, ...,  0.5748927 ,\n",
       "           -0.569789  ,  0.85793924],\n",
       "          [ 0.99055725, -0.46368375,  0.06266975, ...,  0.874152  ,\n",
       "           -0.17188248, -0.88560945],\n",
       "          ...,\n",
       "          [ 0.9965896 , -0.75368935,  0.45074016, ...,  0.04472239,\n",
       "           -0.5157192 ,  0.5981438 ],\n",
       "          [ 0.9901698 , -0.8630062 ,  0.3573836 , ...,  0.6468783 ,\n",
       "           -0.07799593,  0.38569197],\n",
       "          [ 0.99345446, -0.94549894,  0.65810245, ...,  0.7886821 ,\n",
       "           -0.16075467,  0.5711371 ]],\n",
       "  \n",
       "         [[-0.01129138, -0.83206844,  0.41772735, ...,  0.8730926 ,\n",
       "            0.03626674, -0.5693784 ],\n",
       "          [ 0.9878484 , -0.9824737 ,  0.8837424 , ...,  0.9380237 ,\n",
       "            0.15079503,  0.7667458 ],\n",
       "          [ 0.9939184 , -0.97570795,  0.87321305, ..., -0.46184212,\n",
       "           -0.65971303, -0.2605314 ],\n",
       "          ...,\n",
       "          [ 0.99518055, -0.9812281 ,  0.8270348 , ...,  0.84218156,\n",
       "           -0.5581918 ,  0.47191718],\n",
       "          [ 0.9851751 , -0.94313353,  0.73875725, ...,  0.72076035,\n",
       "           -0.02879741,  0.46196994],\n",
       "          [ 0.99106693, -0.9766311 ,  0.86540604, ...,  0.8505235 ,\n",
       "           -0.15562044,  0.6610742 ]],\n",
       "  \n",
       "         [[-0.1171336 , -0.58358973,  0.42610657, ...,  0.90133035,\n",
       "           -0.2222303 , -0.712178  ],\n",
       "          [ 0.9802144 , -0.9774408 ,  0.4828593 , ...,  0.7715326 ,\n",
       "           -0.6737388 ,  0.87062824],\n",
       "          [ 0.99388427, -0.8258552 ,  0.37883174, ..., -0.25368193,\n",
       "           -0.7070627 , -0.60125995],\n",
       "          ...,\n",
       "          [ 0.9958787 , -0.93192536,  0.81263745, ...,  0.8588901 ,\n",
       "           -0.6593563 ,  0.21168822],\n",
       "          [ 0.987356  , -0.8163277 ,  0.69439226, ...,  0.76857626,\n",
       "           -0.21024379,  0.26415244],\n",
       "          [ 0.99290895, -0.92783254,  0.83155274, ...,  0.8871498 ,\n",
       "           -0.271025  ,  0.47728354]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-0.04730845, -0.8574874 ,  0.39812002, ...,  0.8850413 ,\n",
       "            0.1732633 , -0.53151685],\n",
       "          [ 0.977362  , -0.99250376,  0.41892406, ...,  0.6908155 ,\n",
       "           -0.4393173 ,  0.9107676 ],\n",
       "          [ 0.9964634 , -0.96056175,  0.84339064, ...,  0.805615  ,\n",
       "           -0.7570025 , -0.09644087],\n",
       "          ...,\n",
       "          [ 0.9805271 , -0.96765417,  0.23334643, ...,  0.7295795 ,\n",
       "           -0.7741487 , -0.2543417 ],\n",
       "          [ 0.9888913 , -0.97690624, -0.46210715, ...,  0.66838783,\n",
       "            0.08675206, -0.6706094 ],\n",
       "          [ 0.9943312 , -0.94652265,  0.82036686, ...,  0.316687  ,\n",
       "           -0.3122437 ,  0.8764348 ]],\n",
       "  \n",
       "         [[ 0.21897525, -0.75339425,  0.01455246, ...,  0.814804  ,\n",
       "            0.1581397 , -0.38906032],\n",
       "          [ 0.9887189 , -0.9866594 ,  0.1725426 , ...,  0.6198048 ,\n",
       "           -0.5423406 ,  0.91952556],\n",
       "          [ 0.99646944, -0.89832324,  0.04633479, ..., -0.5050478 ,\n",
       "           -0.6727918 , -0.26093236],\n",
       "          ...,\n",
       "          [ 0.9967349 , -0.9609161 ,  0.60971105, ...,  0.7500976 ,\n",
       "           -0.5520963 ,  0.5876634 ],\n",
       "          [ 0.99184006, -0.8812991 ,  0.371349  , ...,  0.60296476,\n",
       "           -0.01791005,  0.5841278 ],\n",
       "          [ 0.99495214, -0.9525584 ,  0.6934669 , ...,  0.7774066 ,\n",
       "           -0.09146798,  0.74655527]],\n",
       "  \n",
       "         [[-0.24436113, -0.7902334 ,  0.51182705, ...,  0.8859604 ,\n",
       "           -0.10646734, -0.75813735],\n",
       "          [ 0.9759261 , -0.9909767 ,  0.5387845 , ...,  0.74167603,\n",
       "           -0.58840245,  0.7683769 ],\n",
       "          [ 0.97648144, -0.97262   ,  0.48849535, ...,  0.78796506,\n",
       "           -0.3871641 , -0.8246331 ],\n",
       "          ...,\n",
       "          [ 0.99485236, -0.97265524,  0.7964437 , ...,  0.805995  ,\n",
       "           -0.60700214,  0.11916068],\n",
       "          [ 0.9853069 , -0.9116522 ,  0.72847056, ...,  0.7301899 ,\n",
       "           -0.11598109,  0.1305288 ],\n",
       "          [ 0.9913687 , -0.9688377 ,  0.8421999 , ...,  0.85660046,\n",
       "           -0.22343922,  0.33498323]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[ 0.21275699, -0.528343  ,  0.03057432, ...,  0.88425434,\n",
       "            0.10622866, -0.62466973],\n",
       "          [ 0.9834388 , -0.9753288 ,  0.27594012, ...,  0.6466402 ,\n",
       "           -0.5939187 ,  0.8111758 ],\n",
       "          [ 0.98800933, -0.3381759 ,  0.18941297, ...,  0.9097158 ,\n",
       "           -0.19459552, -0.86166614],\n",
       "          ...,\n",
       "          [ 0.99613607, -0.7291459 ,  0.43963796, ...,  0.33261237,\n",
       "           -0.46683553,  0.551413  ],\n",
       "          [ 0.98600304, -0.8381896 ,  0.469859  , ...,  0.77522016,\n",
       "           -0.2775103 ,  0.20405896],\n",
       "          [ 0.9901162 , -0.9183026 ,  0.67354256, ...,  0.8367586 ,\n",
       "           -0.13698122,  0.43565324]],\n",
       "  \n",
       "         [[ 0.2658988 , -0.7349983 ,  0.3908766 , ...,  0.9100075 ,\n",
       "            0.15136968, -0.5252532 ],\n",
       "          [ 0.9884065 , -0.97346634,  0.91119975, ...,  0.9451398 ,\n",
       "            0.04298861,  0.71239156],\n",
       "          [ 0.99220794, -0.95917416,  0.8783138 , ..., -0.1372378 ,\n",
       "           -0.6203801 , -0.2646372 ],\n",
       "          ...,\n",
       "          [ 0.9923943 , -0.9658876 ,  0.79891366, ...,  0.8862495 ,\n",
       "           -0.5047408 ,  0.22118622],\n",
       "          [ 0.9823523 , -0.92951   ,  0.79145354, ...,  0.80062926,\n",
       "           -0.18139452,  0.288239  ],\n",
       "          [ 0.98883975, -0.96342593,  0.87384605, ...,  0.87432325,\n",
       "           -0.1093043 ,  0.5525484 ]],\n",
       "  \n",
       "         [[ 0.12021734, -0.39761108,  0.40212464, ...,  0.9374544 ,\n",
       "           -0.13320766, -0.6485018 ],\n",
       "          [ 0.9810719 , -0.96227604,  0.62042165, ...,  0.8243944 ,\n",
       "           -0.69326377,  0.8491282 ],\n",
       "          [ 0.9940582 , -0.77613354,  0.4702668 , ...,  0.00945635,\n",
       "           -0.67187417, -0.52610093],\n",
       "          ...,\n",
       "          [ 0.99322927, -0.8796001 ,  0.77586025, ...,  0.90872115,\n",
       "           -0.63198644, -0.01244376],\n",
       "          [ 0.98420465, -0.77722216,  0.74960685, ...,  0.85241324,\n",
       "           -0.38305435,  0.14160545],\n",
       "          [ 0.9908676 , -0.8905791 ,  0.83120036, ...,  0.915541  ,\n",
       "           -0.23418778,  0.387695  ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.17852701, -0.7994573 ,  0.3724936 , ...,  0.93316585,\n",
       "            0.3045861 , -0.45902374],\n",
       "          [ 0.976865  , -0.988646  ,  0.5717423 , ...,  0.7717658 ,\n",
       "           -0.44671094,  0.8891725 ],\n",
       "          [ 0.9950343 , -0.9560496 ,  0.8809966 , ...,  0.8591452 ,\n",
       "           -0.7172295 ,  0.02176102],\n",
       "          ...,\n",
       "          [ 0.9738644 , -0.96050686,  0.4087098 , ...,  0.8305603 ,\n",
       "           -0.7453263 , -0.35345092],\n",
       "          [ 0.98906493, -0.97970533, -0.41740802, ...,  0.8203976 ,\n",
       "           -0.05909451, -0.61717373],\n",
       "          [ 0.9952712 , -0.93871725,  0.84911954, ...,  0.5624426 ,\n",
       "           -0.26765028,  0.88065237]],\n",
       "  \n",
       "         [[ 0.41570207, -0.68251985, -0.07975352, ...,  0.8787227 ,\n",
       "            0.2496671 , -0.31730467],\n",
       "          [ 0.9882285 , -0.9805692 ,  0.30704057, ...,  0.6972936 ,\n",
       "           -0.5709498 ,  0.8960705 ],\n",
       "          [ 0.9961412 , -0.8838019 ,  0.1095712 , ..., -0.28767285,\n",
       "           -0.6523377 , -0.16562825],\n",
       "          ...,\n",
       "          [ 0.9939865 , -0.93949676,  0.5112247 , ...,  0.8270823 ,\n",
       "           -0.5093011 ,  0.3961892 ],\n",
       "          [ 0.98910517, -0.87884015,  0.42873648, ...,  0.72833645,\n",
       "           -0.20351978,  0.47054735],\n",
       "          [ 0.99296004, -0.9374926 ,  0.673819  , ...,  0.8205172 ,\n",
       "           -0.05551198,  0.67841554]],\n",
       "  \n",
       "         [[-0.05620254, -0.6883474 ,  0.4849845 , ...,  0.93384814,\n",
       "           -0.00282442, -0.74055755],\n",
       "          [ 0.9737045 , -0.98524463,  0.6798189 , ...,  0.8066226 ,\n",
       "           -0.61249274,  0.6885824 ],\n",
       "          [ 0.97475743, -0.94848084,  0.57899266, ...,  0.860866  ,\n",
       "           -0.45373893, -0.79853356],\n",
       "          ...,\n",
       "          [ 0.99041843, -0.95221007,  0.75893104, ...,  0.8788143 ,\n",
       "           -0.56850296, -0.18541318],\n",
       "          [ 0.97891814, -0.89400727,  0.77973866, ...,  0.84045494,\n",
       "           -0.289725  , -0.0920531 ],\n",
       "          [ 0.98730963, -0.9527126 ,  0.84465003, ...,  0.89660966,\n",
       "           -0.1768008 ,  0.15435159]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[ 0.3185443 , -0.35421148,  0.09515455, ...,  0.92306304,\n",
       "            0.2533294 , -0.5973521 ],\n",
       "          [ 0.97685534, -0.9586649 ,  0.4424959 , ...,  0.7062739 ,\n",
       "           -0.586353  ,  0.7370903 ],\n",
       "          [ 0.9818751 , -0.21556649,  0.3564183 , ...,  0.9300011 ,\n",
       "           -0.17003745, -0.82331187],\n",
       "          ...,\n",
       "          [ 0.99461484, -0.69665974,  0.44402647, ...,  0.54543436,\n",
       "           -0.41437778,  0.48769188],\n",
       "          [ 0.97784656, -0.8074998 ,  0.55311006, ...,  0.8576058 ,\n",
       "           -0.35522428,  0.03424196],\n",
       "          [ 0.9830663 , -0.8834289 ,  0.7075727 , ...,  0.86730045,\n",
       "           -0.06565303,  0.292741  ]],\n",
       "  \n",
       "         [[ 0.45443594, -0.58731776,  0.41611388, ...,  0.9317975 ,\n",
       "            0.32481045, -0.48670173],\n",
       "          [ 0.98555136, -0.95712507,  0.9293106 , ...,  0.94707024,\n",
       "           -0.00326179,  0.63205326],\n",
       "          [ 0.98817027, -0.92680526,  0.8884124 , ...,  0.18508787,\n",
       "           -0.5415319 , -0.2739232 ],\n",
       "          ...,\n",
       "          [ 0.98737305, -0.93383414,  0.77485853, ...,  0.9087864 ,\n",
       "           -0.41913107, -0.0266721 ],\n",
       "          [ 0.9773995 , -0.9063754 ,  0.8201748 , ...,  0.854228  ,\n",
       "           -0.2181804 ,  0.11474112],\n",
       "          [ 0.9843496 , -0.94151735,  0.8850392 , ...,  0.8856532 ,\n",
       "           -0.01369414,  0.42529747]],\n",
       "  \n",
       "         [[ 0.30876905, -0.18109263,  0.4330068 , ...,  0.9580222 ,\n",
       "            0.0308657 , -0.5735933 ],\n",
       "          [ 0.9774602 , -0.9334886 ,  0.7151503 , ...,  0.86100847,\n",
       "           -0.6857728 ,  0.8122106 ],\n",
       "          [ 0.9929645 , -0.71838534,  0.5595645 , ...,  0.27816677,\n",
       "           -0.60563076, -0.4250543 ],\n",
       "          ...,\n",
       "          [ 0.988499  , -0.7877849 ,  0.745334  , ...,  0.9353187 ,\n",
       "           -0.5851283 , -0.18314736],\n",
       "          [ 0.9789133 , -0.72496057,  0.7822166 , ...,  0.9041322 ,\n",
       "           -0.4454558 ,  0.04746236],\n",
       "          [ 0.9869332 , -0.83885896,  0.83933055, ...,  0.9304261 ,\n",
       "           -0.15391992,  0.30914494]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.3428716 , -0.7178204 ,  0.39466563, ...,  0.95843667,\n",
       "            0.4706711 , -0.39188883],\n",
       "          [ 0.97099406, -0.9815087 ,  0.6738405 , ...,  0.8289795 ,\n",
       "           -0.4140285 ,  0.8513865 ],\n",
       "          [ 0.991764  , -0.9451432 ,  0.90116686, ...,  0.8910484 ,\n",
       "           -0.64242035,  0.10545874],\n",
       "          ...,\n",
       "          [ 0.9627446 , -0.94919825,  0.5536579 , ...,  0.8867327 ,\n",
       "           -0.69440544, -0.415839  ],\n",
       "          [ 0.98734844, -0.9811332 , -0.31269768, ...,  0.89443165,\n",
       "           -0.13327819, -0.5623686 ],\n",
       "          [ 0.99492234, -0.92931527,  0.8691629 , ...,  0.7235873 ,\n",
       "           -0.19461691,  0.8682089 ]],\n",
       "  \n",
       "         [[ 0.53055495, -0.6000352 , -0.10366519, ...,  0.920293  ,\n",
       "            0.38166955, -0.25527903],\n",
       "          [ 0.98415035, -0.97018987,  0.40692952, ...,  0.7638926 ,\n",
       "           -0.568268  ,  0.8565716 ],\n",
       "          [ 0.99459505, -0.87014073,  0.18737711, ..., -0.00586563,\n",
       "           -0.5981672 , -0.05874549],\n",
       "          ...,\n",
       "          [ 0.98836464, -0.90487474,  0.42504367, ...,  0.8755732 ,\n",
       "           -0.4430697 ,  0.20129965],\n",
       "          [ 0.9840387 , -0.8730337 ,  0.4600227 , ...,  0.820093  ,\n",
       "           -0.27393788,  0.35629758],\n",
       "          [ 0.98886317, -0.9202551 ,  0.6690922 , ...,  0.8514415 ,\n",
       "            0.01863705,  0.6003809 ]],\n",
       "  \n",
       "         [[ 0.09910898, -0.54927284,  0.5037717 , ...,  0.96048236,\n",
       "            0.16274573, -0.72139615],\n",
       "          [ 0.964899  , -0.97391933,  0.77131826, ...,  0.8543664 ,\n",
       "           -0.6111019 ,  0.5716303 ],\n",
       "          [ 0.9693724 , -0.9087527 ,  0.6613103 , ...,  0.9072384 ,\n",
       "           -0.455187  , -0.7694887 ],\n",
       "          ...,\n",
       "          [ 0.981972  , -0.91322505,  0.73283154, ...,  0.920143  ,\n",
       "           -0.5133992 , -0.41190386],\n",
       "          [ 0.96815884, -0.86711365,  0.81087637, ...,  0.9069667 ,\n",
       "           -0.35328224, -0.26834333],\n",
       "          [ 0.9798362 , -0.92837524,  0.8560799 , ...,  0.9210178 ,\n",
       "           -0.09043639, -0.01203175]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[ 0.35335073, -0.20255665,  0.1903141 , ...,  0.94515544,\n",
       "            0.4155832 , -0.5721022 ],\n",
       "          [ 0.96135294, -0.9329421 ,  0.5674888 , ...,  0.75134945,\n",
       "           -0.545888  ,  0.63334054],\n",
       "          [ 0.968867  , -0.12722611,  0.51440305, ...,  0.94172245,\n",
       "           -0.10235948, -0.76971614],\n",
       "          ...,\n",
       "          [ 0.9912177 , -0.665339  ,  0.4565033 , ...,  0.6822624 ,\n",
       "           -0.35555834,  0.40723673],\n",
       "          [ 0.9613051 , -0.78036624,  0.60939896, ...,  0.905334  ,\n",
       "           -0.33622447, -0.0996064 ],\n",
       "          [ 0.96848863, -0.84484965,  0.743478  , ...,  0.8881426 ,\n",
       "            0.04544499,  0.16867019]],\n",
       "  \n",
       "         [[ 0.5537577 , -0.4081919 ,  0.46529183, ...,  0.9433574 ,\n",
       "            0.50819486, -0.4584809 ],\n",
       "          [ 0.977947  , -0.930523  ,  0.9404697 , ...,  0.94455796,\n",
       "            0.01000061,  0.5320736 ],\n",
       "          [ 0.9796532 , -0.8717879 ,  0.8994123 , ...,  0.43406308,\n",
       "           -0.41151974, -0.28192136],\n",
       "          ...,\n",
       "          [ 0.97837603, -0.87493014,  0.7544955 , ...,  0.9191034 ,\n",
       "           -0.29506215, -0.22826906],\n",
       "          [ 0.9683203 , -0.8755686 ,  0.8339205 , ...,  0.8871077 ,\n",
       "           -0.15575479, -0.03075946],\n",
       "          [ 0.97597   , -0.90840775,  0.8948783 , ...,  0.89026517,\n",
       "            0.12357806,  0.2995232 ]],\n",
       "  \n",
       "         [[ 0.42785302,  0.0145282 ,  0.4898781 , ...,  0.9692225 ,\n",
       "            0.23630977, -0.49974442],\n",
       "          [ 0.9679573 , -0.88366294,  0.78049445, ...,  0.8844782 ,\n",
       "           -0.6479374 ,  0.75645036],\n",
       "          [ 0.98992753, -0.6578381 ,  0.6418101 , ...,  0.5053131 ,\n",
       "           -0.50679433, -0.3097602 ],\n",
       "          ...,\n",
       "          [ 0.9801773 , -0.652714  ,  0.72212344, ...,  0.9497129 ,\n",
       "           -0.5107471 , -0.29880214],\n",
       "          [ 0.96935695, -0.6695737 ,  0.80080837, ...,  0.9341236 ,\n",
       "           -0.41902038, -0.01709521],\n",
       "          [ 0.9796853 , -0.7741022 ,  0.85115546, ...,  0.9386283 ,\n",
       "           -0.0305767 ,  0.249459  ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.43729502, -0.6245094 ,  0.4366561 , ...,  0.97129065,\n",
       "            0.6253965 , -0.3419687 ],\n",
       "          [ 0.95763767, -0.96941584,  0.74032646, ...,  0.86648643,\n",
       "           -0.33583212,  0.7915759 ],\n",
       "          [ 0.98465544, -0.9270594 ,  0.9110734 , ...,  0.9105362 ,\n",
       "           -0.51753354,  0.16116464],\n",
       "          ...,\n",
       "          [ 0.9449627 , -0.93313456,  0.6554873 , ...,  0.9167479 ,\n",
       "           -0.6112847 , -0.45565876],\n",
       "          [ 0.98286945, -0.9816683 , -0.15339173, ...,  0.9293333 ,\n",
       "           -0.1342359 , -0.50851804],\n",
       "          [ 0.993346  , -0.9195283 ,  0.8812863 , ...,  0.8188799 ,\n",
       "           -0.08593115,  0.83975554]],\n",
       "  \n",
       "         [[ 0.5779422 , -0.5229712 , -0.08713816, ...,  0.9449136 ,\n",
       "            0.5143184 , -0.2065308 ],\n",
       "          [ 0.9742893 , -0.95434964,  0.48065317, ...,  0.81365806,\n",
       "           -0.53527135,  0.7973099 ],\n",
       "          [ 0.99074143, -0.8588536 ,  0.27386343, ...,  0.28498018,\n",
       "           -0.5156678 ,  0.04783206],\n",
       "          ...,\n",
       "          [ 0.97724783, -0.856962  ,  0.35285956, ...,  0.9054817 ,\n",
       "           -0.3537356 ,  0.03869743],\n",
       "          [ 0.97438896, -0.867793  ,  0.4718228 , ...,  0.8785792 ,\n",
       "           -0.25314224,  0.25921473],\n",
       "          [ 0.98083794, -0.90207213,  0.67125845, ...,  0.87525326,\n",
       "            0.119063  ,  0.5262004 ]],\n",
       "  \n",
       "         [[ 0.19861825, -0.39714503,  0.5421059 , ...,  0.9748355 ,\n",
       "            0.34908178, -0.7042027 ],\n",
       "          [ 0.9459554 , -0.9532053 ,  0.8291273 , ...,  0.8877278 ,\n",
       "           -0.58071184,  0.41725284],\n",
       "          [ 0.95858496, -0.8537735 ,  0.7314682 , ...,  0.93571776,\n",
       "           -0.40916017, -0.74144405],\n",
       "          ...,\n",
       "          [ 0.9666575 , -0.84740883,  0.71644944, ...,  0.9440162 ,\n",
       "           -0.43737245, -0.55536395],\n",
       "          [ 0.9492938 , -0.83498025,  0.8282206 , ...,  0.9438781 ,\n",
       "           -0.32848766, -0.38625598],\n",
       "          [ 0.9664765 , -0.89434457,  0.8694712 , ...,  0.937655  ,\n",
       "            0.02840232, -0.1408704 ]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[ 3.25262129e-01, -1.07285663e-01,  2.83469588e-01, ...,\n",
       "            9.56932425e-01,  5.61048508e-01, -5.49768627e-01],\n",
       "          [ 9.27908719e-01, -8.98861408e-01,  6.55848742e-01, ...,\n",
       "            7.84161747e-01, -4.70638514e-01,  5.04797459e-01],\n",
       "          [ 9.41976964e-01, -9.55232605e-02,  6.35450482e-01, ...,\n",
       "            9.48162675e-01, -1.37686729e-04, -7.02486336e-01],\n",
       "          ...,\n",
       "          [ 9.84075069e-01, -6.44325316e-01,  4.70472038e-01, ...,\n",
       "            7.66083539e-01, -2.86192179e-01,  3.11151594e-01],\n",
       "          [ 9.27668452e-01, -7.65761375e-01,  6.42944336e-01, ...,\n",
       "            9.31415498e-01, -2.42490262e-01, -1.93006814e-01],\n",
       "          [ 9.38836992e-01, -8.09051692e-01,  7.69974291e-01, ...,\n",
       "            9.02700186e-01,  1.79678202e-01,  7.56232962e-02]],\n",
       "  \n",
       "         [[ 5.86190522e-01, -2.39697874e-01,  5.16690969e-01, ...,\n",
       "            9.47842538e-01,  6.62000239e-01, -4.41137254e-01],\n",
       "          [ 9.61611032e-01, -8.92795801e-01,  9.46592212e-01, ...,\n",
       "            9.37978506e-01,  7.44837075e-02,  4.22912329e-01],\n",
       "          [ 9.62196648e-01, -7.94807732e-01,  9.08171475e-01, ...,\n",
       "            5.98142862e-01, -2.24034011e-01, -2.85099417e-01],\n",
       "          ...,\n",
       "          [ 9.62321460e-01, -7.85224915e-01,  7.35816479e-01, ...,\n",
       "            9.22060966e-01, -1.32506371e-01, -3.72937530e-01],\n",
       "          [ 9.51774538e-01, -8.42343986e-01,  8.37394297e-01, ...,\n",
       "            9.05285895e-01, -1.57176405e-02, -1.37449846e-01],\n",
       "          [ 9.60686982e-01, -8.64313483e-01,  9.00544703e-01, ...,\n",
       "            8.90434444e-01,  2.82840759e-01,  1.90858021e-01]],\n",
       "  \n",
       "         [[ 4.82283533e-01,  1.51498020e-01,  5.50257206e-01, ...,\n",
       "            9.74879384e-01,  4.39046741e-01, -4.38199222e-01],\n",
       "          [ 9.48244512e-01, -8.08587134e-01,  8.25799227e-01, ...,\n",
       "            8.98795187e-01, -5.73642015e-01,  6.79666817e-01],\n",
       "          [ 9.83057916e-01, -6.03920102e-01,  7.12214768e-01, ...,\n",
       "            6.67848051e-01, -3.76093179e-01, -1.95462599e-01],\n",
       "          ...,\n",
       "          [ 9.65567231e-01, -4.94729340e-01,  7.04700410e-01, ...,\n",
       "            9.57543790e-01, -4.01355356e-01, -3.73680770e-01],\n",
       "          [ 9.51700926e-01, -6.24398649e-01,  8.10301423e-01, ...,\n",
       "            9.50834751e-01, -3.16037089e-01, -5.88243417e-02],\n",
       "          [ 9.66411889e-01, -7.03216851e-01,  8.61794591e-01, ...,\n",
       "            9.43112075e-01,  1.24896005e-01,  2.07333580e-01]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 4.70274180e-01, -5.39987624e-01,  4.79568243e-01, ...,\n",
       "            9.77617323e-01,  7.44039237e-01, -3.15412760e-01],\n",
       "          [ 9.31580722e-01, -9.50920939e-01,  7.83452511e-01, ...,\n",
       "            8.90486062e-01, -2.09997609e-01,  7.03817964e-01],\n",
       "          [ 9.69477713e-01, -9.02434528e-01,  9.14622545e-01, ...,\n",
       "            9.22718763e-01, -3.30848366e-01,  1.94283664e-01],\n",
       "          ...,\n",
       "          [ 9.16847825e-01, -9.12304580e-01,  7.19163597e-01, ...,\n",
       "            9.32671607e-01, -4.85121459e-01, -4.84259009e-01],\n",
       "          [ 9.73584950e-01, -9.81480479e-01,  3.85389663e-02, ...,\n",
       "            9.45369422e-01, -7.12227374e-02, -4.58594084e-01],\n",
       "          [ 9.89934564e-01, -9.10622478e-01,  8.86649013e-01, ...,\n",
       "            8.72826159e-01,  5.73175400e-02,  7.93823481e-01]],\n",
       "  \n",
       "         [[ 5.72939813e-01, -4.69473451e-01, -5.18572778e-02, ...,\n",
       "            9.58433270e-01,  6.23677850e-01, -1.71719611e-01],\n",
       "          [ 9.53206718e-01, -9.33112442e-01,  5.35809815e-01, ...,\n",
       "            8.47846270e-01, -4.72874016e-01,  7.16713071e-01],\n",
       "          [ 9.81757700e-01, -8.52227628e-01,  3.60679746e-01, ...,\n",
       "            5.20428479e-01, -4.13220406e-01,  1.43389240e-01],\n",
       "          ...,\n",
       "          [ 9.56133187e-01, -8.02812994e-01,  2.91423500e-01, ...,\n",
       "            9.23790932e-01, -2.44113460e-01, -7.86338821e-02],\n",
       "          [ 9.55980062e-01, -8.66421103e-01,  4.69956577e-01, ...,\n",
       "            9.12555993e-01, -1.66023836e-01,  1.87736452e-01],\n",
       "          [ 9.65498626e-01, -8.85007203e-01,  6.71401799e-01, ...,\n",
       "            8.93320024e-01,  2.29495749e-01,  4.65279132e-01]],\n",
       "  \n",
       "         [[ 2.37550825e-01, -2.64931440e-01,  5.81458807e-01, ...,\n",
       "            9.82489109e-01,  5.19523323e-01, -6.91758931e-01],\n",
       "          [ 9.09367859e-01, -9.18876886e-01,  8.65600407e-01, ...,\n",
       "            9.10915852e-01, -5.15931189e-01,  2.36025333e-01],\n",
       "          [ 9.38932121e-01, -7.91105092e-01,  7.87871182e-01, ...,\n",
       "            9.52871859e-01, -3.24952036e-01, -7.17788339e-01],\n",
       "          ...,\n",
       "          [ 9.39766705e-01, -7.52989233e-01,  7.05853760e-01, ...,\n",
       "            9.58302140e-01, -3.35532635e-01, -6.41108811e-01],\n",
       "          [ 9.15807843e-01, -8.03682089e-01,  8.35981548e-01, ...,\n",
       "            9.63621199e-01, -2.32191563e-01, -4.56989765e-01],\n",
       "          [ 9.42868292e-01, -8.51058483e-01,  8.79728913e-01, ...,\n",
       "            9.49707210e-01,  1.66677207e-01, -2.30906174e-01]]],\n",
       "        dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[ 0.24249955, -0.07464552,  0.35717735, ...,  0.96236783,\n",
       "            0.6749432 , -0.529854  ],\n",
       "          [ 0.85963786, -0.8604527 ,  0.7159094 , ...,  0.80747133,\n",
       "           -0.35977954,  0.3632819 ],\n",
       "          [ 0.8884697 , -0.12565553,  0.716533  , ...,  0.95090574,\n",
       "            0.1249643 , -0.626633  ],\n",
       "          ...,\n",
       "          [ 0.9694691 , -0.63931763,  0.4812235 , ...,  0.8177031 ,\n",
       "           -0.20127693,  0.20237748],\n",
       "          [ 0.8618019 , -0.766691  ,  0.6590232 , ...,  0.9447601 ,\n",
       "           -0.09505667, -0.25315556],\n",
       "          [ 0.8808638 , -0.78161526,  0.7829267 , ...,  0.9123966 ,\n",
       "            0.3181126 ,  0.01182513]],\n",
       "  \n",
       "         [[ 0.5688403 , -0.11688826,  0.5593741 , ...,  0.9467938 ,\n",
       "            0.7721575 , -0.4306757 ],\n",
       "          [ 0.9288813 , -0.84728897,  0.9489754 , ...,  0.9270029 ,\n",
       "            0.17761362,  0.31531316],\n",
       "          [ 0.92766374, -0.70941985,  0.91300744, ...,  0.69776756,\n",
       "            0.00907396, -0.28243   ],\n",
       "          ...,\n",
       "          [ 0.93421507, -0.67711544,  0.7164739 , ...,  0.9198608 ,\n",
       "            0.05892903, -0.46904692],\n",
       "          [ 0.9223011 , -0.81372964,  0.83357406, ...,  0.91287315,\n",
       "            0.17026885, -0.20760553],\n",
       "          [ 0.9334156 , -0.81360275,  0.9007935 , ...,  0.88653773,\n",
       "            0.44035158,  0.1058109 ]],\n",
       "  \n",
       "         [[ 0.48312396,  0.22248831,  0.6021919 , ...,  0.97707033,\n",
       "            0.606189  , -0.3931235 ],\n",
       "          [ 0.9099773 , -0.7137778 ,  0.85730654, ...,  0.90680945,\n",
       "           -0.45525968,  0.58298504],\n",
       "          [ 0.9680811 , -0.56543714,  0.76815575, ...,  0.771191  ,\n",
       "           -0.21699911, -0.09571899],\n",
       "          ...,\n",
       "          [ 0.9401076 , -0.3514425 ,  0.6903626 , ...,  0.961531  ,\n",
       "           -0.25149247, -0.42180976],\n",
       "          [ 0.91924924, -0.59965897,  0.8139508 , ...,  0.9595555 ,\n",
       "           -0.1472277 , -0.08590899],\n",
       "          [ 0.9422927 , -0.6365823 ,  0.8683081 , ...,  0.9450569 ,\n",
       "            0.2939094 ,  0.17683417]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.45142618, -0.48061717,  0.5148046 , ...,  0.9803649 ,\n",
       "            0.8248905 , -0.31047997],\n",
       "          [ 0.8837453 , -0.9258052 ,  0.81152403, ...,  0.9056522 ,\n",
       "           -0.04280096,  0.58566076],\n",
       "          [ 0.9382127 , -0.8743352 ,  0.9135248 , ...,  0.9302355 ,\n",
       "           -0.08879896,  0.20784286],\n",
       "          ...,\n",
       "          [ 0.87294126, -0.8876545 ,  0.7546477 , ...,  0.941008  ,\n",
       "           -0.30921417, -0.50821877],\n",
       "          [ 0.9554856 , -0.980552  ,  0.23012449, ...,  0.95167273,\n",
       "            0.04063834, -0.4159967 ],\n",
       "          [ 0.9832736 , -0.90351003,  0.8862544 , ...,  0.90285003,\n",
       "            0.2236718 ,  0.72901726]],\n",
       "  \n",
       "         [[ 0.5239229 , -0.44877017, -0.01113196, ...,  0.9650392 ,\n",
       "            0.7043767 , -0.14841832],\n",
       "          [ 0.91081315, -0.908526  ,  0.5778655 , ...,  0.86975396,\n",
       "           -0.38268787,  0.61711305],\n",
       "          [ 0.9613896 , -0.851508  ,  0.43977976, ...,  0.67759234,\n",
       "           -0.3001533 ,  0.22050886],\n",
       "          ...,\n",
       "          [ 0.9182363 , -0.7551394 ,  0.23624426, ...,  0.93469226,\n",
       "           -0.11830517, -0.15502062],\n",
       "          [ 0.9217445 , -0.87019247,  0.46029928, ...,  0.9306694 ,\n",
       "           -0.03737674,  0.1407457 ],\n",
       "          [ 0.93716383, -0.8711422 ,  0.6633121 , ...,  0.90587074,\n",
       "            0.33652008,  0.41977248]],\n",
       "  \n",
       "         [[ 0.22054009, -0.17211871,  0.6132583 , ...,  0.9865157 ,\n",
       "            0.65502816, -0.68472093],\n",
       "          [ 0.84330815, -0.86828494,  0.88888615, ...,  0.9271508 ,\n",
       "           -0.41029978,  0.04762281],\n",
       "          [ 0.9046425 , -0.73160595,  0.8308743 , ...,  0.9630073 ,\n",
       "           -0.20861357, -0.7002447 ],\n",
       "          ...,\n",
       "          [ 0.893888  , -0.64055806,  0.6974556 , ...,  0.9670784 ,\n",
       "           -0.20342219, -0.6925554 ],\n",
       "          [ 0.85749096, -0.77844244,  0.8374283 , ...,  0.9740084 ,\n",
       "           -0.08040864, -0.49686   ],\n",
       "          [ 0.9018083 , -0.8010302 ,  0.8846756 , ...,  0.9584271 ,\n",
       "            0.31010342, -0.2924949 ]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(16, 17, 74), dtype=float32, numpy=\n",
       "  array([[[ 0.11644447, -0.09187873,  0.4076971 , ...,  0.9636118 ,\n",
       "            0.7571747 , -0.5110888 ],\n",
       "          [ 0.733303  , -0.82309264,  0.7556795 , ...,  0.82348424,\n",
       "           -0.21696025,  0.22215371],\n",
       "          [ 0.79041797, -0.20682375,  0.76648575, ...,  0.9506919 ,\n",
       "            0.25912714, -0.5496664 ],\n",
       "          ...,\n",
       "          [ 0.94100285, -0.65018433,  0.48662785, ...,  0.85029626,\n",
       "           -0.0972191 ,  0.08604456],\n",
       "          [ 0.74399066, -0.77898693,  0.6629465 , ...,  0.95040894,\n",
       "            0.07866119, -0.29034153],\n",
       "          [ 0.7757696 , -0.76414794,  0.7823024 , ...,  0.91794294,\n",
       "            0.4457039 , -0.03129583]],\n",
       "  \n",
       "         [[ 0.510791  , -0.05028407,  0.5909282 , ...,  0.940499  ,\n",
       "            0.8443841 , -0.42104566],\n",
       "          [ 0.8681368 , -0.80094343,  0.94837236, ...,  0.9105429 ,\n",
       "            0.3027556 ,  0.21665943],\n",
       "          [ 0.8637036 , -0.6354259 ,  0.91322523, ...,  0.7550344 ,\n",
       "            0.25333935, -0.27442485],\n",
       "          ...,\n",
       "          [ 0.88700086, -0.57598   ,  0.694911  , ...,  0.9132206 ,\n",
       "            0.259822  , -0.5286924 ],\n",
       "          [ 0.87202996, -0.7945671 ,  0.82482255, ...,  0.911982  ,\n",
       "            0.36214942, -0.24866213],\n",
       "          [ 0.8864629 , -0.7633692 ,  0.8952429 , ...,  0.8779226 ,\n",
       "            0.5780267 ,  0.04352982]],\n",
       "  \n",
       "         [[ 0.4391452 ,  0.23780818,  0.64227676, ...,  0.97679293,\n",
       "            0.72826046, -0.36149684],\n",
       "          [ 0.8403428 , -0.61514497,  0.87920755, ...,  0.9102709 ,\n",
       "           -0.28870833,  0.47174454],\n",
       "          [ 0.9365358 , -0.54564273,  0.8098167 , ...,  0.8324366 ,\n",
       "           -0.03622734, -0.01828473],\n",
       "          ...,\n",
       "          [ 0.89688754, -0.25227597,  0.6768789 , ...,  0.9629678 ,\n",
       "           -0.06255719, -0.45263153],\n",
       "          [ 0.86171865, -0.5973611 ,  0.8141268 , ...,  0.9632284 ,\n",
       "            0.06414012, -0.10490038],\n",
       "          [ 0.89951223, -0.58307374,  0.86958516, ...,  0.94484466,\n",
       "            0.4561419 ,  0.1513847 ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.38761178, -0.4505233 ,  0.5406918 , ...,  0.9809301 ,\n",
       "            0.87691545, -0.32004473],\n",
       "          [ 0.80168855, -0.8956697 ,  0.8297451 , ...,  0.9149721 ,\n",
       "            0.14706838,  0.44187847],\n",
       "          [ 0.8780527 , -0.8472601 ,  0.9082264 , ...,  0.9344687 ,\n",
       "            0.1741147 ,  0.20407215],\n",
       "          ...,\n",
       "          [ 0.8063798 , -0.8609738 ,  0.77053   , ...,  0.9451323 ,\n",
       "           -0.08990964, -0.5296318 ],\n",
       "          [ 0.9217362 , -0.97873473,  0.3943857 , ...,  0.9522413 ,\n",
       "            0.18055356, -0.38346633],\n",
       "          [ 0.9706552 , -0.89837676,  0.88077855, ...,  0.9191274 ,\n",
       "            0.3930194 ,  0.6457688 ]],\n",
       "  \n",
       "         [[ 0.4362207 , -0.45820972,  0.02903283, ...,  0.9671656 ,\n",
       "            0.76116025, -0.13270113],\n",
       "          [ 0.8328943 , -0.884066  ,  0.61052555, ...,  0.88263553,\n",
       "           -0.26857334,  0.504498  ],\n",
       "          [ 0.9180346 , -0.8556914 ,  0.50600386, ...,  0.7709729 ,\n",
       "           -0.18358193,  0.27588484],\n",
       "          ...,\n",
       "          [ 0.8553636 , -0.7247746 ,  0.18496367, ...,  0.94061965,\n",
       "            0.01847045, -0.20088756],\n",
       "          [ 0.86175877, -0.877863  ,  0.44849867, ...,  0.93876845,\n",
       "            0.10657947,  0.11172473],\n",
       "          [ 0.8874858 , -0.86145717,  0.64426327, ...,  0.91321266,\n",
       "            0.4326673 ,  0.38623276]],\n",
       "  \n",
       "         [[ 0.156503  , -0.11859012,  0.63600993, ...,  0.9885147 ,\n",
       "            0.7537604 , -0.68179005],\n",
       "          [ 0.7345856 , -0.8022559 ,  0.90398175, ...,  0.9385972 ,\n",
       "           -0.2601877 , -0.12784313],\n",
       "          [ 0.8477006 , -0.6822551 ,  0.86228967, ...,  0.9687821 ,\n",
       "           -0.06736063, -0.68870384],\n",
       "          ...,\n",
       "          [ 0.8190459 , -0.52858585,  0.6893873 , ...,  0.97251934,\n",
       "           -0.04104262, -0.7246368 ],\n",
       "          [ 0.76165897, -0.760619  ,  0.8352579 , ...,  0.9793217 ,\n",
       "            0.10315924, -0.5194621 ],\n",
       "          [ 0.83272725, -0.74740684,  0.88395435, ...,  0.964487  ,\n",
       "            0.4463259 , -0.3376989 ]]], dtype=float32)>]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.501221>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    item[1][\"labels\"], result[\"token_logits\"]\n",
    ") * tf.cast(item[1][\"label_mask\"], tf.float32)) / tf.reduce_sum(tf.cast(item[1][\"label_mask\"], tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers.losses import cross_entropy_loss_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_loss(y_true_dict, token_logits):\n",
    "    loss = cross_entropy_loss_fast(\n",
    "        labels=y_true_dict[\"labels\"],\n",
    "        logits=token_logits,\n",
    "        label_weights=y_true_dict[\"label_mask\"],\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def token_loss_all_layers(y_true_dict, y_pred_dict):\n",
    "    layer_loss = []\n",
    "    for token_logits in y_pred_dict['token_logits']:\n",
    "        loss = token_loss(y_true_dict, token_logits)\n",
    "        layer_loss.append(loss)\n",
    "    return tf.reduce_mean(layer_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.513224>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_loss_all_layers(item[1], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_to_new_index, aligned_words, sub_words_mapped = fast_sp_alignment(df_train['words'][0], \n",
    "                                                                        tokenizer, \n",
    "                                                                        SPECIAL_PIECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Add',\n",
       " 'Don',\n",
       " 'and',\n",
       " 'Sherri',\n",
       " 'to',\n",
       " 'my',\n",
       " 'Meditate',\n",
       " 'to',\n",
       " 'Sounds',\n",
       " 'of',\n",
       " 'Nature',\n",
       " 'playlist']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "        sentence = row[\"words\"]\n",
    "        labels = row[\"word_labels\"]\n",
    "        word_tokens = sentence.split()\n",
    "        label_tokens = labels.split()\n",
    "#         if len(word_tokens) != len(label_tokens):\n",
    "#             ignored_index.append(index)\n",
    "#             continue\n",
    "        flat_tokens, flat_labels = tokenize_and_align_sentence_label(\n",
    "            sentence, word_tokens, label_tokens, label_pad_token=\"[PAD]\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁add',\n",
       " '▁don',\n",
       " '▁and',\n",
       " '▁sherri',\n",
       " '▁to',\n",
       " '▁my',\n",
       " '▁med',\n",
       " 'itate',\n",
       " '▁to',\n",
       " '▁sounds',\n",
       " '▁of',\n",
       " '▁nature',\n",
       " '▁playlist']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-entity_name',\n",
       " 'I-entity_name',\n",
       " 'I-entity_name',\n",
       " 'O',\n",
       " 'B-playlist_owner',\n",
       " 'B-playlist',\n",
       " '[PAD]',\n",
       " 'I-playlist',\n",
       " 'I-playlist',\n",
       " 'I-playlist',\n",
       " 'I-playlist',\n",
       " 'O']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = {}\n",
    "sample_inputs['input_ids'] = tf.constant([tokenizer.convert_tokens_to_ids(flat_tokens)])\n",
    "sample_inputs['input_mask'] = tf.ones_like(sample_inputs['input_ids'])\n",
    "sample_inputs['input_type_ids'] = tf.zeros_like(sample_inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = token_classification_model(sample_inputs)\n",
    "token_logits = result['token_logits'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 13), dtype=int64, numpy=array([[41, 40, 41, 41, 41, 41, 45,  6, 41, 41, 41, 41, 41]])>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(token_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁add'] 1 (0, 1)\n",
      "['▁don'] 1 (1, 2)\n",
      "['▁and'] 1 (2, 3)\n",
      "['▁sherri'] 1 (3, 4)\n",
      "['▁to'] 1 (4, 5)\n",
      "['▁my'] 1 (5, 6)\n",
      "['▁med', 'itate'] 2 (6, 8)\n",
      "['▁to'] 1 (8, 9)\n",
      "['▁sounds'] 1 (9, 10)\n",
      "['▁of'] 1 (10, 11)\n",
      "['▁nature'] 1 (11, 12)\n",
      "['▁playlist'] 1 (12, 13)\n"
     ]
    }
   ],
   "source": [
    "start_index = 0\n",
    "for item in sub_words_mapped:\n",
    "    end_index = start_index + len(item)\n",
    "    print(item, len(item), (start_index, end_index))\n",
    "    start_index = end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_like_this(input_list, output_list):\n",
    "    \n",
    "    start_index = 0\n",
    "    for current_index, item in input_list:\n",
    "        end_index = start_index + len(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
