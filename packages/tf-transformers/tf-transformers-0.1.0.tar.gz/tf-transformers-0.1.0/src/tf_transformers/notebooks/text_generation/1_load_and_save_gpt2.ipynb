{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/PRVATE/Documents/tf_transformers/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFGPT2Model\n",
    "from tf_transformers.models import GPT2Encoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from tf_transformers.core import LegacyModule\n",
    "from tf_transformers.utils import convert_gpt2_hf_to_tf_transformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at /Users/PRVATE/HUggingFace_Models/gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load HF model\n",
    "\n",
    "# Always do this\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "local_dir = \"/Users/PRVATE/HUggingFace_Models/\"\n",
    "hf_model_name = \"gpt2\"\n",
    "if local_dir:\n",
    "    hf_model_location = local_dir + hf_model_name\n",
    "\n",
    "model_hf = TFGPT2Model.from_pretrained(hf_model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training`                     to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids_1:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:Deleteing huggingface model for saving memory\n",
      "INFO:absl:Done assigning variables weights . Total 100\n"
     ]
    }
   ],
   "source": [
    "# Load tf_transformers model\n",
    "# Most config we will be providing\n",
    "\n",
    "# Default configs for the model\n",
    "\n",
    "model_config_dir = \"/Users/PRVATE/Documents/tf_transformers/model_configs/\"\n",
    "model_name = \"gpt2_base\"\n",
    "config_location = os.path.join(model_config_dir, model_name, \"config.json\")\n",
    "config = json.load(open(config_location))\n",
    "\n",
    "# Always do this\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# tf_transformers Layer (an extension of Keras Layer)\n",
    "# This is not Keras model, but extension of keras Layer\n",
    "\n",
    "# Save as saved_model\n",
    "# If you want to use the model for Auto Regressive tasks ( text-generation ),\n",
    "# you have to enable pipeline_mode='auto-regressive'.\n",
    "# Because TF needs extra cache inputs in the saved_model format for doing efficient caching\n",
    "\n",
    "model_layer = GPT2Encoder(\n",
    "    config=config,\n",
    "    name=\"gpt2\",\n",
    "    mask_mode=config[\"mask_mode\"],\n",
    "    is_training=False,\n",
    ")\n",
    "\n",
    "# Convert to tf.keras.Model\n",
    "model_tf_transformers = model_layer.get_and_load_model(model_dir=None)\n",
    "convert_gpt2_hf_to_tf_transformers(model_hf, model_tf_transformers, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Deleteing huggingface model for saving memory\n",
      "INFO:absl:Done assigning variables weights . Total 100\n"
     ]
    }
   ],
   "source": [
    "# Load model variables from HF to tf_transformers\n",
    "convert_gpt2_hf_to_tf_transformers(model_hf, model_tf_transformers, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embeddings --> tf.Tensor(2371.2754, shape=(), dtype=float32) --> (2, 5, 768)\n",
      "token_logits --> tf.Tensor(-34781264.0, shape=(), dtype=float32) --> (2, 5, 50257)\n",
      "last_token_logits --> tf.Tensor(-8346981.0, shape=(), dtype=float32) --> (2, 50257)\n"
     ]
    }
   ],
   "source": [
    "# Please have a look at tf_transformers/extra/*.py for reference values\n",
    "\n",
    "input_ids = tf.constant([[1, 9, 10, 11, 23], [1, 22, 234, 432, 2349]])\n",
    "\n",
    "input_mask = tf.ones_like(input_ids)\n",
    "input_type_ids = tf.zeros_like(input_ids)\n",
    "\n",
    "inputs = {\n",
    "    \"input_ids\": input_ids,\n",
    "}\n",
    "\n",
    "results_tf_transformers = model_tf_transformers(inputs)\n",
    "for k, r in results_tf_transformers.items():\n",
    "    if isinstance(r, list):\n",
    "        continue\n",
    "    print(k, \"-->\", tf.reduce_sum(r), \"-->\", r.shape)\n",
    "\n",
    "\n",
    "# For GPT2 Base\n",
    "\n",
    "# token_embeddings --> tf.Tensor(2371.2751, shape=(), dtype=float32) --> (2, 5, 768)\n",
    "# token_logits --> tf.Tensor(-34781260.0, shape=(), dtype=float32) --> (2, 5, 50257)\n",
    "# last_token_logits --> tf.Tensor(-8346980.5, shape=(), dtype=float32) --> (2, 50257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at model_ckpt/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "# If you want to save the model as checkpoints\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(model=model_tf_transformers)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory=\"model_ckpt\", max_to_keep=1)\n",
    "manager.save()\n",
    "print(\"Saved at {}\".format(manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids_2:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:past_length ---> Tensor(\"past_length:0\", shape=(1, None), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids_3:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:all_cache_key ---> Tensor(\"all_cache_key_1:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:all_cache_value ---> Tensor(\"all_cache_value_1:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:past_length ---> Tensor(\"past_length_1:0\", shape=(1, None), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.gpt2.GPT2Encoder object at 0x14622d1c0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x147ee9be0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.gpt2.GPT2Encoder object at 0x14622d1c0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x147ee9be0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint matched\n"
     ]
    }
   ],
   "source": [
    "# Save as saved_model\n",
    "# If you want to use the model for Auto Regressive tasks ( text-generation ),\n",
    "# you have to enable pipeline_mode='auto-regressive'.\n",
    "# Because TF needs extra cache inputs in the saved_model format for doing efficient caching\n",
    "\n",
    "model_layer = GPT2Encoder(\n",
    "    config=config,\n",
    "    name=\"gpt2\",\n",
    "    mask_mode=config[\"mask_mode\"],\n",
    "    is_training=False,\n",
    "    pipeline_mode=\"auto-regressive\",\n",
    ")\n",
    "\n",
    "# Convert to tf.keras.Model\n",
    "model_tf_transformers = model_layer.get_and_load_model(model_dir=None)\n",
    "\n",
    "# And now load the checkpints from previously saved model\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(model=model_tf_transformers)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory=\"model_ckpt\", max_to_keep=1)\n",
    "status = checkpoint.restore(manager.latest_checkpoint)\n",
    "\n",
    "# Important\n",
    "if status.assert_existing_objects_matched():\n",
    "    print(\"Model checkpoint matched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor 'input_ids_3:0' shape=(None, None) dtype=int32>,\n",
       " 'all_cache_key': <tf.Tensor 'all_cache_key_1:0' shape=(None, None, 12, None, 64) dtype=float32>,\n",
       " 'all_cache_value': <tf.Tensor 'all_cache_value_1:0' shape=(None, None, 12, None, 64) dtype=float32>,\n",
       " 'past_length': <tf.Tensor 'past_length_1:0' shape=(1, None) dtype=int32>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf_transformers.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we load the model , now save it to .pb (saved_model)\n",
    "\n",
    "# The problem with this approach is , TF somewhow changes the names of the output nodes\n",
    "# We need to preserve it to have consistent TextDecoder class for all models\n",
    "# So, we have LegacyModule, which will take care of this\n",
    "\n",
    "\n",
    "# model_tf_transformers.save(\"model_pb\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_pb/assets\n"
     ]
    }
   ],
   "source": [
    "gpt2_module = LegacyModule(model_tf_transformers)\n",
    "gpt2_module.save(\"model_pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done :-) . Go to 1_text_generation_gpt2 for how to do text-generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
