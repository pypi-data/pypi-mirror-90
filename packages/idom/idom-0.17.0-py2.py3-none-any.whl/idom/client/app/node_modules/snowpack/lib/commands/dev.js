"use strict";
/**
 * This license applies to parts of this file originating from the
 * https://github.com/lukejacksonn/servor repository:
 *
 * MIT License
 * Copyright (c) 2019 Luke Jackson
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.command = exports.startServer = void 0;
const cacache_1 = __importDefault(require("cacache"));
const compressible_1 = __importDefault(require("compressible"));
const deepmerge_1 = __importDefault(require("deepmerge"));
const etag_1 = __importDefault(require("etag"));
const events_1 = require("events");
const fs_1 = require("fs");
const got_1 = __importDefault(require("got"));
const http_1 = __importDefault(require("http"));
const http_proxy_1 = __importDefault(require("http-proxy"));
const http2_1 = __importDefault(require("http2"));
const https_1 = __importDefault(require("https"));
const colors = __importStar(require("kleur/colors"));
const mime_types_1 = __importDefault(require("mime-types"));
const os_1 = __importDefault(require("os"));
const path_1 = __importDefault(require("path"));
const perf_hooks_1 = require("perf_hooks");
const signal_exit_1 = __importDefault(require("signal-exit"));
const stream_1 = __importDefault(require("stream"));
const url_1 = __importDefault(require("url"));
const util_1 = __importDefault(require("util"));
const zlib_1 = __importDefault(require("zlib"));
const build_import_proxy_1 = require("../build/build-import-proxy");
const build_pipeline_1 = require("../build/build-pipeline");
const import_resolver_1 = require("../build/import-resolver");
const src_file_extension_mapping_1 = __importDefault(require("../build/src-file-extension-mapping"));
const hmr_server_engine_1 = require("../hmr-server-engine");
const logger_1 = require("../logger");
const rewrite_imports_1 = require("../rewrite-imports");
const scan_imports_1 = require("../scan-imports");
const util_2 = require("../util");
const install_1 = require("./install");
const paint_1 = require("./paint");
const DEFAULT_PROXY_ERROR_HANDLER = (err, req, res) => {
    const reqUrl = req.url;
    logger_1.logger.error(`✘ ${reqUrl}\n${err.message}`);
    sendError(req, res, 502);
};
/**
 * An in-memory build cache for Snowpack. Responsible for coordinating
 * different builds (ex: SSR, non-SSR) to get/set individually but clear
 * both at once.
 */
class InMemoryBuildCache {
    constructor() {
        this.ssrCache = new Map();
        this.webCache = new Map();
    }
    getCache(isSSR) {
        if (isSSR) {
            return this.ssrCache;
        }
        else {
            return this.webCache;
        }
    }
    get(fileLoc, isSSR) {
        return this.getCache(isSSR).get(fileLoc);
    }
    set(fileLoc, val, isSSR) {
        return this.getCache(isSSR).set(fileLoc, val);
    }
    has(fileLoc, isSSR) {
        return this.getCache(isSSR).has(fileLoc);
    }
    delete(fileLoc) {
        this.getCache(true).delete(fileLoc);
        this.getCache(false).delete(fileLoc);
    }
    clear() {
        this.getCache(true).clear();
        this.getCache(false).clear();
    }
}
function shouldProxy(pathPrefix, req) {
    const reqPath = decodeURI(url_1.default.parse(req.url).pathname);
    return reqPath.startsWith(pathPrefix);
}
const sendFile = (req, res, body, fileLoc, ext = '.html') => {
    var _a;
    body = Buffer.from(body);
    const ETag = etag_1.default(body, { weak: true });
    const contentType = mime_types_1.default.contentType(ext);
    const headers = {
        'Accept-Ranges': 'bytes',
        'Access-Control-Allow-Origin': '*',
        'Content-Type': contentType || 'application/octet-stream',
        ETag,
        Vary: 'Accept-Encoding',
    };
    if (req.headers['if-none-match'] === ETag) {
        res.writeHead(304, headers);
        res.end();
        return;
    }
    let acceptEncoding = req.headers['accept-encoding'] || '';
    if (((_a = req.headers['cache-control']) === null || _a === void 0 ? void 0 : _a.includes('no-transform')) ||
        ['HEAD', 'OPTIONS'].includes(req.method) ||
        !contentType ||
        !compressible_1.default(contentType)) {
        acceptEncoding = '';
    }
    // Handle gzip compression
    if (/\bgzip\b/.test(acceptEncoding) && stream_1.default.Readable.from) {
        const bodyStream = stream_1.default.Readable.from([body]);
        headers['Content-Encoding'] = 'gzip';
        res.writeHead(200, headers);
        stream_1.default.pipeline(bodyStream, zlib_1.default.createGzip(), res, function onError(err) {
            if (err) {
                res.end();
                logger_1.logger.error(`✘ An error occurred serving ${colors.bold(req.url)}`);
                logger_1.logger.error(typeof err !== 'string' ? err.toString() : err);
            }
        });
        return;
    }
    // Handle partial requests
    const { range } = req.headers;
    if (range) {
        const { size: fileSize } = fs_1.statSync(fileLoc);
        const [rangeStart, rangeEnd] = range.replace(/bytes=/, '').split('-');
        const start = parseInt(rangeStart, 10);
        const end = rangeEnd ? parseInt(rangeEnd, 10) : fileSize - 1;
        const chunkSize = end - start + 1;
        const fileStream = fs_1.createReadStream(fileLoc, { start, end });
        res.writeHead(206, {
            ...headers,
            'Content-Range': `bytes ${start}-${end}/${fileSize}`,
            'Content-Length': chunkSize,
        });
        fileStream.pipe(res);
        return;
    }
    res.writeHead(200, headers);
    res.write(body);
    res.end();
};
const sendError = (req, res, status) => {
    const contentType = mime_types_1.default.contentType(path_1.default.extname(req.url) || '.html');
    const headers = {
        'Access-Control-Allow-Origin': '*',
        'Accept-Ranges': 'bytes',
        'Content-Type': contentType || 'application/octet-stream',
        Vary: 'Accept-Encoding',
    };
    res.writeHead(status, headers);
    res.end();
};
function getUrlFromFile(mountedDirectories, fileLoc, config) {
    for (const [dirDisk, dirUrl] of mountedDirectories) {
        if (fileLoc.startsWith(dirDisk + path_1.default.sep)) {
            const { baseExt } = util_2.getExt(fileLoc);
            const resolvedDirUrl = dirUrl === '/' ? '' : dirUrl;
            return util_2.replaceExt(fileLoc.replace(dirDisk, resolvedDirUrl).replace(/[/\\]+/g, '/'), baseExt, config._extensionMap[baseExt] || src_file_extension_mapping_1.default[baseExt] || baseExt);
        }
    }
    return null;
}
async function startServer(commandOptions) {
    const { cwd, config } = commandOptions;
    const { port: defaultPort, hostname, open } = config.devOptions;
    const isHmr = typeof config.devOptions.hmr !== 'undefined' ? config.devOptions.hmr : true;
    // Start the startup timer!
    let serverStart = perf_hooks_1.performance.now();
    const port = await paint_1.getPort(defaultPort);
    // Reset the clock if we had to wait for the user to select a new port.
    if (port !== defaultPort) {
        serverStart = perf_hooks_1.performance.now();
    }
    const messageBus = new events_1.EventEmitter();
    // note: this would cause an infinite loop if not for the logger.on(…) in
    // `paint.ts`.
    console.log = (...args) => {
        logger_1.logger.info(util_1.default.format(...args));
    };
    console.warn = (...args) => {
        logger_1.logger.warn(util_1.default.format(...args));
    };
    console.error = (...args) => {
        logger_1.logger.error(util_1.default.format(...args));
    };
    paint_1.paint(messageBus, config.plugins.map((p) => p.name));
    const inMemoryBuildCache = new InMemoryBuildCache();
    const filesBeingDeleted = new Set();
    const filesBeingBuilt = new Map();
    const mountedDirectories = Object.entries(config.mount).map(([fromDisk, toUrl]) => {
        return [path_1.default.resolve(cwd, fromDisk), toUrl];
    });
    // Set the proper install options, in case an install is needed.
    const dependencyImportMapLoc = path_1.default.join(util_2.DEV_DEPENDENCIES_DIR, 'import-map.json');
    logger_1.logger.debug(`Using cache folder: ${path_1.default.relative(cwd, util_2.DEV_DEPENDENCIES_DIR)}`);
    const installCommandOptions = deepmerge_1.default(commandOptions, {
        config: {
            installOptions: {
                dest: util_2.DEV_DEPENDENCIES_DIR,
                env: { NODE_ENV: process.env.NODE_ENV || 'development' },
                treeshake: false,
            },
        },
    });
    // Start with a fresh install of your dependencies, if needed.
    if (!(await util_2.checkLockfileHash(util_2.DEV_DEPENDENCIES_DIR)) || !fs_1.existsSync(dependencyImportMapLoc)) {
        logger_1.logger.debug('Cache out of date or missing. Updating…');
        logger_1.logger.info(colors.yellow('! updating dependencies...'));
        await install_1.command(installCommandOptions);
        await util_2.updateLockfileHash(util_2.DEV_DEPENDENCIES_DIR);
    }
    else {
        logger_1.logger.debug(`Cache up-to-date. Using existing cache`);
    }
    let dependencyImportMap = { imports: {} };
    try {
        dependencyImportMap = JSON.parse(await fs_1.promises.readFile(dependencyImportMapLoc, { encoding: 'utf-8' }));
    }
    catch (err) {
        // no import-map found, safe to ignore
    }
    const devProxies = {};
    config.proxy.forEach(([pathPrefix, proxyOptions]) => {
        const proxyServer = (devProxies[pathPrefix] = http_proxy_1.default.createProxyServer(proxyOptions));
        for (const [onEventName, eventHandler] of Object.entries(proxyOptions.on)) {
            proxyServer.on(onEventName, eventHandler);
        }
        if (!proxyOptions.on.error) {
            proxyServer.on('error', DEFAULT_PROXY_ERROR_HANDLER);
        }
        logger_1.logger.info(`Proxy created: ${pathPrefix} -> ${proxyOptions.target || proxyOptions.forward}`);
    });
    const readCredentials = async (cwd) => {
        const [cert, key] = await Promise.all([
            fs_1.promises.readFile(path_1.default.join(cwd, 'snowpack.crt')),
            fs_1.promises.readFile(path_1.default.join(cwd, 'snowpack.key')),
        ]);
        return {
            cert,
            key,
        };
    };
    let credentials;
    if (config.devOptions.secure) {
        try {
            credentials = await readCredentials(cwd);
        }
        catch (e) {
            logger_1.logger.error(`✘ No HTTPS credentials found! Missing Files:  ${colors.bold('snowpack.crt')}, ${colors.bold('snowpack.key')}`);
            logger_1.logger.info(`You can automatically generate credentials for your project via either:

  - ${colors.cyan('devcert')}: ${colors.yellow('npx devcert-cli generate localhost')}
    https://github.com/davewasmer/devcert-cli (no install required)

  - ${colors.cyan('mkcert')}: ${colors.yellow('mkcert -install && mkcert -key-file snowpack.key -cert-file snowpack.crt localhost')}

    https://github.com/FiloSottile/mkcert (install required)`);
            process.exit(1);
        }
    }
    for (const runPlugin of config.plugins) {
        if (runPlugin.run) {
            runPlugin
                .run({
                isDev: true,
                isHmrEnabled: isHmr,
                // @ts-ignore: internal API only
                log: (msg, data) => {
                    messageBus.emit(msg, { ...data, id: runPlugin.name });
                },
            })
                .then(() => {
                logger_1.logger.info('Command completed.', { name: runPlugin.name });
            })
                .catch((err) => {
                logger_1.logger.error(`Command exited with error code: ${err}`, { name: runPlugin.name });
                process.exit(1);
            });
        }
    }
    async function requestHandler(req, res) {
        var _a;
        const reqUrl = req.url;
        const reqUrlHmrParam = reqUrl.includes('?mtime=') && reqUrl.split('?')[1];
        let reqPath = decodeURI(url_1.default.parse(reqUrl).pathname);
        const originalReqPath = reqPath;
        const isSSR = reqUrl.includes('?ssr');
        let isProxyModule = false;
        let isSourceMap = false;
        if (reqPath.endsWith('.proxy.js')) {
            isProxyModule = true;
            reqPath = util_2.replaceExt(reqPath, '.proxy.js', '');
        }
        else if (reqPath.endsWith('.map')) {
            isSourceMap = true;
            reqPath = util_2.replaceExt(reqPath, '.map', '');
        }
        res.on('finish', () => {
            const { method, url } = req;
            const { statusCode } = res;
            if (statusCode !== 200) {
                messageBus.emit(paint_1.paintEvent.SERVER_RESPONSE, {
                    method,
                    url,
                    statusCode,
                });
            }
        });
        if (reqPath === build_import_proxy_1.getMetaUrlPath('/hmr-client.js', config)) {
            sendFile(req, res, util_2.HMR_CLIENT_CODE, reqPath, '.js');
            return;
        }
        if (reqPath === build_import_proxy_1.getMetaUrlPath('/hmr-error-overlay.js', config)) {
            sendFile(req, res, util_2.HMR_OVERLAY_CODE, reqPath, '.js');
            return;
        }
        if (reqPath === build_import_proxy_1.getMetaUrlPath('/env.js', config)) {
            sendFile(req, res, build_import_proxy_1.generateEnvModule('development'), reqPath, '.js');
            return;
        }
        for (const [pathPrefix] of config.proxy) {
            if (!shouldProxy(pathPrefix, req)) {
                continue;
            }
            devProxies[pathPrefix].web(req, res);
            return;
        }
        const attemptedFileLoads = [];
        function attemptLoadFile(requestedFile) {
            if (attemptedFileLoads.includes(requestedFile)) {
                return Promise.resolve(null);
            }
            attemptedFileLoads.push(requestedFile);
            return fs_1.promises
                .stat(requestedFile)
                .then((stat) => (stat.isFile() ? requestedFile : null))
                .catch(() => null /* ignore */);
        }
        let requestedFile = path_1.default.parse(reqPath);
        let requestedFileExt = requestedFile.ext.toLowerCase();
        let responseFileExt = requestedFileExt;
        let isRoute = !requestedFileExt || requestedFileExt === '.html';
        // Now that we've set isRoute properly, give `requestedFileExt` a fallback
        requestedFileExt = requestedFileExt || '.html';
        async function getFileFromUrl(reqPath) {
            if (reqPath.startsWith(config.buildOptions.webModulesUrl)) {
                const fileLoc = await attemptLoadFile(reqPath.replace(config.buildOptions.webModulesUrl, util_2.DEV_DEPENDENCIES_DIR));
                if (fileLoc) {
                    return fileLoc;
                }
            }
            for (const [dirDisk, dirUrl] of mountedDirectories) {
                let requestedFile;
                if (dirUrl === '/') {
                    requestedFile = path_1.default.join(dirDisk, reqPath);
                }
                else if (reqPath.startsWith(dirUrl)) {
                    requestedFile = path_1.default.join(dirDisk, reqPath.replace(dirUrl, './'));
                }
                else {
                    continue;
                }
                if (isRoute) {
                    let fileLoc = (await attemptLoadFile(requestedFile)) ||
                        (await attemptLoadFile(requestedFile + '.html')) ||
                        (await attemptLoadFile(requestedFile + 'index.html')) ||
                        (await attemptLoadFile(requestedFile + '/index.html'));
                    if (!fileLoc && dirUrl === '/' && config.devOptions.fallback) {
                        const fallbackFile = path_1.default.join(dirDisk, config.devOptions.fallback);
                        fileLoc = await attemptLoadFile(fallbackFile);
                    }
                    if (fileLoc) {
                        responseFileExt = '.html';
                        return fileLoc;
                    }
                }
                else {
                    for (const potentialSourceFile of build_pipeline_1.getInputsFromOutput(requestedFile, config.plugins)) {
                        const fileLoc = await attemptLoadFile(potentialSourceFile);
                        if (fileLoc) {
                            return fileLoc;
                        }
                    }
                }
            }
            return null;
        }
        const fileLoc = await getFileFromUrl(reqPath);
        if (!fileLoc) {
            const prefix = colors.red('  ✘ ');
            logger_1.logger.error(`[404] ${reqUrl}\n${attemptedFileLoads.map((loc) => prefix + loc).join('\n')}`);
            return sendError(req, res, 404);
        }
        /**
         * Given a file, build it. Building a file sends it through our internal
         * file builder pipeline, and outputs a build map representing the final
         * build. A Build Map is used because one source file can result in multiple
         * built files (Example: .svelte -> .js & .css).
         */
        async function buildFile(fileLoc) {
            const existingBuilderPromise = filesBeingBuilt.get(fileLoc);
            if (existingBuilderPromise) {
                return existingBuilderPromise;
            }
            const fileBuilderPromise = (async () => {
                const builtFileOutput = await build_pipeline_1.buildFile(fileLoc, {
                    plugins: config.plugins,
                    isDev: true,
                    isSSR,
                    isHmrEnabled: isHmr,
                    sourceMaps: config.buildOptions.sourceMaps,
                });
                inMemoryBuildCache.set(fileLoc, builtFileOutput, isSSR);
                return builtFileOutput;
            })();
            filesBeingBuilt.set(fileLoc, fileBuilderPromise);
            try {
                messageBus.emit(paint_1.paintEvent.BUILD_FILE, { id: fileLoc, isBuilding: true });
                return await fileBuilderPromise;
            }
            finally {
                filesBeingBuilt.delete(fileLoc);
                messageBus.emit(paint_1.paintEvent.BUILD_FILE, { id: fileLoc, isBuilding: false });
            }
        }
        /**
         * Wrap Response: The same build result can be expressed in different ways
         * based on the URL. For example, "App.css" should return CSS but
         * "App.css.proxy.js" should return a JS representation of that CSS. This is
         * handled in the wrap step.
         */
        async function wrapResponse(code, { hasCssResource, sourceMap, sourceMappingURL, }) {
            // transform special requests
            if (isRoute) {
                code = build_import_proxy_1.wrapHtmlResponse({
                    code: code,
                    hmr: isHmr,
                    isDev: true,
                    config,
                    mode: 'development',
                });
            }
            else if (isProxyModule) {
                responseFileExt = '.js';
            }
            else if (isSourceMap && sourceMap) {
                responseFileExt = '.map';
                code = sourceMap;
            }
            // transform other files
            switch (responseFileExt) {
                case '.css': {
                    if (sourceMap)
                        code = util_2.cssSourceMappingURL(code, sourceMappingURL);
                    break;
                }
                case '.js': {
                    if (isProxyModule) {
                        code = await build_import_proxy_1.wrapImportProxy({ url: reqPath, code, hmr: isHmr, config });
                    }
                    else {
                        code = build_import_proxy_1.wrapImportMeta({ code: code, env: true, hmr: isHmr, config });
                    }
                    if (hasCssResource)
                        code =
                            `import './${path_1.default.basename(reqPath).replace(/.js$/, '.css.proxy.js')}';\n` + code;
                    // source mapping
                    if (sourceMap)
                        code = util_2.jsSourceMappingURL(code, sourceMappingURL);
                    break;
                }
            }
            // by default, return file from disk
            return code;
        }
        /**
         * Resolve Imports: Resolved imports are based on the state of the file
         * system, so they can't be cached long-term with the build.
         */
        async function resolveResponseImports(fileLoc, responseExt, wrappedResponse) {
            const resolveImportSpecifier = import_resolver_1.createImportResolver({
                fileLoc,
                dependencyImportMap,
                config,
            });
            wrappedResponse = await rewrite_imports_1.transformFileImports({
                locOnDisk: fileLoc,
                contents: wrappedResponse,
                baseExt: responseExt,
                expandedExt: util_2.getExt(fileLoc).expandedExt,
            }, (spec) => {
                // Try to resolve the specifier to a known URL in the project
                const resolvedImportUrl = resolveImportSpecifier(spec);
                if (resolvedImportUrl) {
                    // Ignore "http://*" imports
                    if (url_1.default.parse(resolvedImportUrl).protocol) {
                        return resolvedImportUrl;
                    }
                    // Support proxy file imports
                    const extName = path_1.default.extname(resolvedImportUrl);
                    if (extName &&
                        (responseExt === '.js' || responseExt === '.html') &&
                        extName !== '.js') {
                        return resolvedImportUrl + '.proxy.js';
                    }
                    return resolvedImportUrl;
                }
                const errorTitle = `Error: Import "${spec}" could not be resolved.`;
                const errorMessage = `If this is a new package, re-run Snowpack with the ${colors.bold('--reload')} flag to rebuild.
If Snowpack is having trouble detecting the import, add ${colors.bold(`"install": ["${spec}"]`)} to your Snowpack config file.`;
                logger_1.logger.error(`${errorTitle}\n${errorMessage}`);
                hmrEngine.broadcastMessage({
                    type: 'error',
                    title: `${errorTitle}`,
                    errorMessage,
                    fileLoc,
                });
                return spec;
            });
            let code = wrappedResponse;
            if (responseFileExt === '.js' && reqUrlHmrParam)
                code = await rewrite_imports_1.transformEsmImports(code, (imp) => {
                    const importUrl = path_1.default.posix.resolve(path_1.default.posix.dirname(reqPath), imp);
                    const node = hmrEngine.getEntry(importUrl);
                    if (node && node.needsReplacement) {
                        hmrEngine.markEntryForReplacement(node, false);
                        return `${imp}?${reqUrlHmrParam}`;
                    }
                    return imp;
                });
            if (responseFileExt === '.js') {
                const isHmrEnabled = code.includes('import.meta.hot');
                const rawImports = await rewrite_imports_1.scanCodeImportsExports(code);
                const resolvedImports = rawImports.map((imp) => {
                    let spec = code.substring(imp.s, imp.e);
                    if (imp.d > -1) {
                        spec = scan_imports_1.matchDynamicImportValue(spec) || '';
                    }
                    spec = spec.replace(/\?mtime=[0-9]+$/, '');
                    return path_1.default.posix.resolve(path_1.default.posix.dirname(reqPath), spec);
                });
                hmrEngine.setEntry(originalReqPath, resolvedImports, isHmrEnabled);
            }
            wrappedResponse = code;
            return wrappedResponse;
        }
        /**
         * Given a build, finalize it for the response. This involves running
         * individual steps needed to go from build result to sever response,
         * including:
         *   - wrapResponse(): Wrap responses
         *   - resolveResponseImports(): Resolve all ESM imports
         */
        async function finalizeResponse(fileLoc, requestedFileExt, output) {
            // Verify that the requested file exists in the build output map.
            if (!output[requestedFileExt] || !Object.keys(output)) {
                return null;
            }
            const { code, map } = output[requestedFileExt];
            let finalResponse = code;
            // Wrap the response.
            const hasAttachedCss = requestedFileExt === '.js' && !!output['.css'];
            finalResponse = await wrapResponse(finalResponse, {
                hasCssResource: hasAttachedCss,
                sourceMap: map,
                sourceMappingURL: path_1.default.basename(requestedFile.base) + '.map',
            });
            // Resolve imports.
            if (requestedFileExt === '.js' ||
                requestedFileExt === '.html' ||
                requestedFileExt === '.css') {
                finalResponse = await resolveResponseImports(fileLoc, requestedFileExt, finalResponse);
            }
            // Return the finalized response.
            return finalResponse;
        }
        // 1. Check the hot build cache. If it's already found, then just serve it.
        let hotCachedResponse = inMemoryBuildCache.get(fileLoc, isSSR);
        if (hotCachedResponse) {
            const responseContent = await finalizeResponse(fileLoc, requestedFileExt, hotCachedResponse);
            if (!responseContent) {
                sendError(req, res, 404);
                return;
            }
            sendFile(req, res, responseContent, fileLoc, responseFileExt);
            return;
        }
        // 2. Load the file from disk. We'll need it to check the cold cache or build from scratch.
        const fileContents = await util_2.readFile(fileLoc);
        // 3. Send dependencies directly, since they were already build & resolved
        // at install time.
        if (reqPath.startsWith(config.buildOptions.webModulesUrl) && !isProxyModule) {
            sendFile(req, res, fileContents, fileLoc, responseFileExt);
            return;
        }
        // 4. Check the persistent cache. If found, serve it via a
        // "trust-but-verify" strategy. Build it after sending, and if it no longer
        // matches then assume the entire cache is suspect. In that case, clear the
        // persistent cache and then force a live-reload of the page.
        const cachedBuildData = !isSSR &&
            !filesBeingDeleted.has(fileLoc) &&
            (await cacache_1.default.get(util_2.BUILD_CACHE, fileLoc).catch(() => null));
        if (cachedBuildData) {
            const { originalFileHash } = cachedBuildData.metadata;
            const newFileHash = etag_1.default(fileContents);
            if (originalFileHash === newFileHash) {
                // IF THIS FAILS TS CHECK: If you are changing the structure of
                // SnowpackBuildMap, be sure to also update `BUILD_CACHE` in util.ts to
                // a new unique name, to guarantee a clean cache for our users.
                const coldCachedResponse = JSON.parse(cachedBuildData.data.toString());
                inMemoryBuildCache.set(fileLoc, coldCachedResponse, false);
                // Trust...
                const wrappedResponse = await finalizeResponse(fileLoc, requestedFileExt, coldCachedResponse);
                if (!wrappedResponse) {
                    sendError(req, res, 404);
                    return;
                }
                sendFile(req, res, wrappedResponse, fileLoc, responseFileExt);
                // ...but verify.
                let checkFinalBuildResult = null;
                try {
                    checkFinalBuildResult = await buildFile(fileLoc);
                }
                catch (err) {
                    // safe to ignore, it will be surfaced later anyway
                }
                finally {
                    if (!checkFinalBuildResult ||
                        !cachedBuildData.data.equals(Buffer.from(JSON.stringify(checkFinalBuildResult)))) {
                        inMemoryBuildCache.clear();
                        await cacache_1.default.rm.all(util_2.BUILD_CACHE);
                        hmrEngine.broadcastMessage({ type: 'reload' });
                    }
                }
                return;
            }
        }
        // 5. Final option: build the file, serve it, and cache it.
        let responseContent;
        let responseOutput;
        try {
            responseOutput = await buildFile(fileLoc);
        }
        catch (err) {
            logger_1.logger.error(err.toString(), { name: (_a = err.__snowpackBuildDetails) === null || _a === void 0 ? void 0 : _a.name });
            hmrEngine.broadcastMessage({
                type: 'error',
                title: `Build Error` + err.__snowpackBuildDetails ? `: ${err.__snowpackBuildDetails.name}` : '',
                errorMessage: err.toString(),
                fileLoc,
                errorStackTrace: err.stack,
            });
            sendError(req, res, 500);
            return;
        }
        try {
            responseContent = await finalizeResponse(fileLoc, requestedFileExt, responseOutput);
        }
        catch (err) {
            logger_1.logger.error(`${reqPath}
${err}`);
            sendError(req, res, 500);
            return;
        }
        if (!responseContent) {
            sendError(req, res, 404);
            return;
        }
        sendFile(req, res, responseContent, fileLoc, responseFileExt);
        const originalFileHash = etag_1.default(fileContents);
        // Only save the file to our cold cache if it's not SSR.
        // NOTE(fks): We could do better and cache both, but at the time of writing SSR
        // is still a new concept. Lets confirm that this is how we want to do SSR, and
        // then can revisit the caching story once confident.
        if (!isSSR) {
            cacache_1.default.put(util_2.BUILD_CACHE, fileLoc, Buffer.from(JSON.stringify(responseOutput)), {
                metadata: { originalFileHash },
            });
        }
    }
    const createServer = (requestHandler) => {
        if (credentials && config.proxy.length === 0) {
            return http2_1.default.createSecureServer({ ...credentials, allowHTTP1: true }, requestHandler);
        }
        else if (credentials) {
            return https_1.default.createServer(credentials, requestHandler);
        }
        return http_1.default.createServer(requestHandler);
    };
    const server = createServer((req, res) => {
        /** Handle errors not handled in our requestHandler. */
        function onUnhandledError(err) {
            logger_1.logger.error(`[500] ${req.url}`);
            logger_1.logger.error(err.toString());
            sendError(req, res, 500);
        }
        // If custom "app" is given, pass requests through there first.
        if (config.experiments.app) {
            config.experiments.app(req, res, (err) => {
                if (err) {
                    onUnhandledError(err);
                }
                else {
                    requestHandler(req, res).catch(onUnhandledError);
                }
            });
            return;
        }
        // Otherwise, pass requests directly to Snowpack's request handler.
        requestHandler(req, res).catch(onUnhandledError);
    })
        .on('error', (err) => {
        logger_1.logger.error(colors.red(`  ✘ Failed to start server at port ${colors.bold(port)}.`), err);
        server.close();
        process.exit(1);
    })
        .on('upgrade', (req, socket, head) => {
        config.proxy.forEach(([pathPrefix, proxyOptions]) => {
            var _a;
            const isWebSocket = proxyOptions.ws || ((_a = proxyOptions.target) === null || _a === void 0 ? void 0 : _a.toString().startsWith('ws'));
            if (isWebSocket && shouldProxy(pathPrefix, req)) {
                devProxies[pathPrefix].ws(req, socket, head);
                logger_1.logger.info('Upgrading to WebSocket');
            }
        });
    })
        .listen(port);
    const { hmrDelay } = config.devOptions;
    const hmrEngine = new hmr_server_engine_1.EsmHmrEngine({ server, delay: hmrDelay });
    signal_exit_1.default(() => {
        hmrEngine.disconnectAllClients();
    });
    // Live Reload + File System Watching
    let isLiveReloadPaused = false;
    function updateOrBubble(url, visited) {
        if (visited.has(url)) {
            return;
        }
        visited.add(url);
        const node = hmrEngine.getEntry(url);
        if (node && node.isHmrEnabled) {
            hmrEngine.broadcastMessage({ type: 'update', url });
        }
        if (node && node.isHmrAccepted) {
            // Found a boundary, no bubbling needed
        }
        else if (node && node.dependents.size > 0) {
            node.dependents.forEach((dep) => {
                hmrEngine.markEntryForReplacement(node, true);
                updateOrBubble(dep, visited);
            });
        }
        else {
            // We've reached the top, trigger a full page refresh
            hmrEngine.broadcastMessage({ type: 'reload' });
        }
    }
    function handleHmrUpdate(fileLoc) {
        if (isLiveReloadPaused) {
            return;
        }
        let updateUrl = getUrlFromFile(mountedDirectories, fileLoc, config);
        if (!updateUrl) {
            return;
        }
        // Append ".proxy.js" to Non-JS files to match their registered URL in the
        // client app.
        if (!updateUrl.endsWith('.js')) {
            updateUrl += '.proxy.js';
        }
        // Check if a virtual file exists in the resource cache (ex: CSS from a
        // Svelte file) If it does, mark it for HMR replacement but DONT trigger a
        // separate HMR update event. This is because a virtual resource doesn't
        // actually exist on disk, so we need the main resource (the JS) to load
        // first. Only after that happens will the CSS exist.
        const virtualCssFileUrl = updateUrl.replace(/.js$/, '.css');
        const virtualNode = hmrEngine.getEntry(`${virtualCssFileUrl}.proxy.js`);
        if (virtualNode) {
            hmrEngine.markEntryForReplacement(virtualNode, true);
        }
        // If the changed file exists on the page, trigger a new HMR update.
        if (hmrEngine.getEntry(updateUrl)) {
            updateOrBubble(updateUrl, new Set());
            return;
        }
        // Otherwise, reload the page if the file exists in our hot cache (which
        // means that the file likely exists on the current page, but is not
        // supported by HMR (HTML, image, etc)).
        if (inMemoryBuildCache.has(fileLoc, false)) {
            hmrEngine.broadcastMessage({ type: 'reload' });
            return;
        }
    }
    // Announce server has started
    const ips = Object.values(os_1.default.networkInterfaces())
        .reduce((every, i) => [...every, ...(i || [])], [])
        .filter((i) => i.family === 'IPv4' && i.internal === false)
        .map((i) => i.address);
    const protocol = config.devOptions.secure ? 'https:' : 'http:';
    messageBus.emit(paint_1.paintEvent.SERVER_START, {
        protocol,
        hostname,
        port,
        ips,
        startTimeMs: Math.round(perf_hooks_1.performance.now() - serverStart),
    });
    // Open the user's browser
    if (open !== 'none') {
        await util_2.openInBrowser(protocol, hostname, port, open);
    }
    // Start watching the file system.
    // Defer "chokidar" loading to here, to reduce impact on overall startup time
    const chokidar = await Promise.resolve().then(() => __importStar(require('chokidar')));
    // Watch src files
    async function onWatchEvent(fileLoc) {
        logger_1.logger.info(colors.cyan('File changed...'));
        handleHmrUpdate(fileLoc);
        inMemoryBuildCache.delete(fileLoc);
        filesBeingDeleted.add(fileLoc);
        await cacache_1.default.rm.entry(util_2.BUILD_CACHE, fileLoc);
        filesBeingDeleted.delete(fileLoc);
    }
    const watcher = chokidar.watch(mountedDirectories.map(([dirDisk]) => dirDisk), {
        ignored: config.exclude,
        persistent: true,
        ignoreInitial: true,
        disableGlobbing: false,
    });
    watcher.on('add', (fileLoc) => onWatchEvent(fileLoc));
    watcher.on('change', (fileLoc) => onWatchEvent(fileLoc));
    watcher.on('unlink', (fileLoc) => onWatchEvent(fileLoc));
    // Watch node_modules & rerun snowpack install if symlinked dep updates
    const symlinkedFileLocs = new Set(Object.keys(dependencyImportMap.imports)
        .map((specifier) => {
        const [packageName] = util_2.parsePackageImportSpecifier(specifier);
        return util_2.resolveDependencyManifest(packageName, cwd);
    }) // resolve symlink src location
        .filter(([_, packageManifest]) => packageManifest && !packageManifest['_id']) // only watch symlinked deps for now
        .map(([fileLoc]) => `${path_1.default.dirname(fileLoc)}/**`));
    function onDepWatchEvent() {
        hmrEngine.broadcastMessage({ type: 'reload' });
    }
    const depWatcher = chokidar.watch([...symlinkedFileLocs], {
        cwd: '/',
        persistent: true,
        ignoreInitial: true,
        disableGlobbing: false,
    });
    depWatcher.on('add', onDepWatchEvent);
    depWatcher.on('change', onDepWatchEvent);
    depWatcher.on('unlink', onDepWatchEvent);
    return {
        requestHandler,
        /** @experimental - only available via unstable__startServer */
        async loadByUrl(url, { isSSR }) {
            if (!url.startsWith('/')) {
                throw new Error(`url must start with "/", but got ${url}`);
            }
            return (await got_1.default.get(`http://localhost:${port}${url}${isSSR ? '?ssr=1' : ''}`)).body;
        },
    };
}
exports.startServer = startServer;
async function command(commandOptions) {
    await startServer(commandOptions);
    return new Promise(() => { });
}
exports.command = command;
//# sourceMappingURL=dev.js.map