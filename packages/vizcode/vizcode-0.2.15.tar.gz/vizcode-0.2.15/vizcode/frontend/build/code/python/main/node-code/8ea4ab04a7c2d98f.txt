def full_json_with_matching(projects_df, title, charity_amount, num_of_processes=2):    global doc1    doc1 = nlp(remove_stop_words(title))    projects_df.set_index('project_id', drop=True, inplace=True)    df_split = np.array_split(projects_df, num_of_processes)  # partition df    pool = Pool(num_of_processes)    sim_df = pd.concat(pool.map(get_similarities, df_split))    pool.close()    pool.join()    top_ids = sim_df.nlargest(charity_amount).index    return [int(i) for i in top_ids]