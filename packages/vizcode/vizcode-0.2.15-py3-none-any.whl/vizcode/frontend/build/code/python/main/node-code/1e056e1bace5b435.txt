def get_charities():    """    Gets the recommended projects for an article.    :param: request.form params: article link    :return: Info for each recommended project.    """    return jsonify([])    charity_amount = application.config['CHARITY_AMOUNT']    num_choices = application.config['NUM_CHOICES']    article_url = request.form.get('article_link').split('?')[0]    article_url = article_url.split('#')[0]    if redis.exists(article_url):        # Get from the redis cache        charity_match = pickle.loads(redis.get(article_url))        return jsonify(charity_match)    else:        print('checking article')        # Check the article        article = Article.query.filter_by(article_link=article_url).first()        # article exists        if article:            print('article exists')            widget_status = article.widget_status            print(widget_status)            if widget_status:                # get number of ids that are not null and assume nulls follow consecutively                project_ids = article.get_project_ids()                if None in project_ids:                    num_ids = project_ids.index(None)                else:                    num_ids = charity_amount                project_info_list = get_projects_from_article(article_url=article_url, num_ids=num_ids)                # Save to redis cache                redis.set(article_url, pickle.dumps(project_info_list))                return jsonify(project_info_list)            else:                return jsonify([])        else:            widget_status = True            article_title = request.form.get('article_title')            # testing client on local host            if article_title == '':                article_info = indiana_scraper(article_url)                article_title = article_info['title']                article_date_time = article_info['date']            else:                article_date_time = datetime.strptime(request.form.get('article_date'), "%b %d %Y")                article_text = request.form.get('article_text').replace(u'\xa0', u'')                # store article data in a json file and upload to a s3 bucket                save_article_data(s3_client=s3, article_link=article_url, article_title=article_title,                                  article_date_time=article_date_time, article_text=article_text)                # turn off widget for too old articles                date_cut_off = datetime.strptime('Jun 28 2020', '%b %d %Y')                if article_date_time < date_cut_off:                    widget_status = False            # select projects that are not removed and are from verified charities            projects_df = get_available_projects()            project_ids = [None for i in range(charity_amount)]            matching_project_ids = full_json_with_matching(projects_df, article_title,                                                           num_choices)  # relevant project ids            for i in range(len(matching_project_ids)):                project_ids[i] = matching_project_ids[i]            # all_project_ids = list(projects_df['project_id'])            # project_ids = [None for i in range(charity_amount)]            # random_project_ids = random.sample(all_project_ids, num_choices)            # for i in range(len(random_project_ids)):            #     project_ids[i] = random_project_ids[i]            # Add to database            article = Article(                article_link=article_url,                article_title=article_title,                publisher_id="Indiana Daily Student",                widget_status=widget_status,                date_published=article_date_time,                fund_name=None,                project_id1=project_ids[0],                project_id2=project_ids[1],                project_id3=project_ids[2],                project_id4=project_ids[3],                project_id5=project_ids[4],                project_id6=project_ids[5],                edited_by_publisher=False,                edited_by_newspark=False,            )            db.session.add(article)            db.session.commit()            if widget_status:                project_info_list = get_projects_from_article(article_url=article_url, num_ids=num_choices)                # Save to redis cache                redis.set(article_url, pickle.dumps(project_info_list))                return jsonify(project_info_list)            else:                return jsonify([])