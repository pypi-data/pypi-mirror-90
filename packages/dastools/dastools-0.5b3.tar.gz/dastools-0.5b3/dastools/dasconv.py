#!/usr/bin/env python3
# -*- coding: utf-8 -*-

###############################################################################
# (C) 2020 Helmholtz-Zentrum Potsdam - Deutsches GeoForschungsZentrum GFZ     #
#                                                                             #
# Licensed under the EUPL, Version 1.1 or â€“ as soon theywill be approved by   #
# the European Commission - subsequent versions of the EUPL (the "Licence");  #
# You may not use this work except in compliance with theLicence.             #
# You may obtain a copy of the Licence at:                                    #
# https://joinup.ec.europa.eu/software/page/eupl                              #
# Unless required by applicable law or agreed to in writing, software         #
# distributed under the Licence is distributed on an "AS IS" basis,           #
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    #
# See the Licence for the specific language governing permissions and         #
# limitations under the Licence.                                              #
###############################################################################

import argparse
import sys
import logging
import pprint
import datetime
from obspy import Trace
from .tdms import TDMS
from dastools import __version__
import dastools.archive as da
import inspect


def nslc(dataheader):
    """Get a NSLC code from a dictionary with its components

    :param dataheader: Dictionry with components of a NSLC code
    :type dataheader: dict
    :return: NSLC code
    :rtype: str
    """
    return '%s.%s.%s.%s' % (dataheader['network'].upper(), dataheader['station'].upper(),
                            dataheader['location'].upper(), dataheader['channel'].upper())


def printmetadata(data):
    """Print the data in a pretty format

    Take into account the special case of a dictionary.
    """
    if isinstance(data, dict):
        pprint.pprint(data)
    else:
        print(data)


def str2date(dstr):
    """Transform a string to a datetime.

    :param dstr: A datetime in ISO format.
    :type dstr: string
    :return: A datetime represented the converted input.
    :rtype: datetime.datetime
    """
    # In case of empty string
    if (dstr is None) or (not len(dstr)):
        return None

    dateparts = dstr.replace('-', ' ').replace('T', ' ')
    dateparts = dateparts.replace(':', ' ').replace('.', ' ')
    dateparts = dateparts.replace('Z', '').split()
    # Consider the case in which just the first digits of microseconds
    # are given and complete with 0's to have 6 digits
    if len(dateparts) == 7:
        dateparts[6] = dateparts[6] + '0' * (6 - len(dateparts[6]))

    return datetime.datetime(*map(int, dateparts))


def main():
    # Inspect the archive.py module to list the Classes based on Archive
    dictarchive = dict()
    for name, obj in inspect.getmembers(da):
        if inspect.isclass(obj):
            if issubclass(obj, da.Archive) and name != 'Archive':
                dictarchive[name] = obj

    helparchive = 'Available options are [%s]' % ', '.join(dictarchive.keys())

    # Check verbosity in the output
    msg = 'Read, manipulate and convert seismic waveforms generated by a DAS system.'
    parser = argparse.ArgumentParser(description=msg)
    parser.add_argument('-l', '--loglevel',
                        help='Verbosity in the output.',
                        choices=['CRITICAL', 'ERROR', 'WARNING', 'INFO',
                                 'DEBUG'],
                        default='WARNING')
    parser.add_argument('-d', '--directory',
                        help='Directory where files are located (default: ".")',
                        default='.')
    parser.add_argument('--start', '--starttime',
                        help='Start of the selected time window.\nFormat: 2019-02-01T00:01:02.123456Z',
                        default=None)
    parser.add_argument('--end', '--endtime',
                        help='End of the selected time window.\nFormat: 2019-02-01T00:01:02.123456Z',
                        default=None)
    parser.add_argument('--chstart', type=int,
                        help='First channel to export',
                        default=0)
    parser.add_argument('--chstop', type=int,
                        help='Last channel to export',
                        default=None)
    parser.add_argument('--chstep', type=int,
                        help='Step between channels in the selection',
                        default=1)
    parser.add_argument('--decimate', type=int, choices=[1, 5],
                        help='Factor by which the sampling rate is lowered by decimation.',
                        default=1)
    parser.add_argument('-o', '--outstruct', type=str, choices=dictarchive.keys(),
                        help=helparchive, default='StreamBased')
    parser.add_argument('--metadata', action='store_true', default=False,
                        help='Read and display the metadata from the TDMS files')
    parser.add_argument('-V', '--version', action='version', version='dasconv v%s' % __version__)
    parser.add_argument('filename',
                        help='Experiment to read and process. It is usually the first part of the filenames.')

    args = parser.parse_args()
    if args.metadata:
        logging.basicConfig(level=args.loglevel, stream=sys.stdout)
    else:
        logging.basicConfig(level=args.loglevel)

    logs = logging.getLogger('OpenFile')
    logs.setLevel(args.loglevel)

    dtstart = str2date(args.start)
    dtend = str2date(args.end)

    if dtend is not None and dtstart is not None and dtstart >= dtend:
        logs.error('End time is smaller than Start time.')
        return

    td = TDMS(args.filename, directory=args.directory, iterate='M' if args.metadata else 'D',
              chstart=args.chstart, chstop=args.chstop, chstep=args.chstep,
              starttime=dtstart, endtime=dtend, decimate=args.decimate)

    # Selected archive structure
    # Archive files in current directory
    klass = dictarchive[args.outstruct]
    archive = klass(root='.', experiment=args.filename, strictcheck=False)

    expectedtimes = dict()

    with td:
        curstream = None

        for data in td:
            if args.metadata:
                printmetadata(data)
            else:
                logs.debug(data[1])

                if curstream != nslc(data[1]):
                    # Save the previous Stream completely
                    if curstream is not None:
                        archive.archive(tr0)
                        logs.info('Storing channel %s. Starttime: %s' % (curstream, data[1].get('starttime', None)))

                    # Update which stream is being processed
                    curstream = nslc(data[1])
                    # Create the Trace
                    tr0 = Trace(data=data[0], header=data[1])
                else:
                    # Check if there is a gap in the signal. If a gap is detected, flush now
                    if data[1]['starttime'] != expectedtimes[curstream]:
                        archive.archive(tr0)
                        tr0 = Trace(data=data[0], header=data[1])
                    else:
                        tr0 += Trace(data=data[0], header=data[1])

                # Update the datetime of the expected sample
                expectedtimes[curstream] = data[1]['starttime'] + data[1]['npts']/data[1]['sampling_rate']
        else:
            if not args.metadata:
                logs.info('Storing last part of channel %s' % curstream)
                try:
                    archive.archive(tr0)
                except KeyError:
                    archive.archive(tr0)

                except UnboundLocalError:
                    logs.error('Signal was not processed. Probably too short!')


if __name__ == '__main__':
    main()
