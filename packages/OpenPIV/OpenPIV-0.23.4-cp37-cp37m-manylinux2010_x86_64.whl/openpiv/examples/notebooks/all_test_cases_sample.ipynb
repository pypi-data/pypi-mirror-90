{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenPIV tutorial of all test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpiv import tools, pyprocess, scaling, validation, filters\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.5\n",
      "IPython version      : 7.19.0\n",
      "\n",
      "numpy  : 1.19.4\n",
      "openpiv: 0.23.3b0\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-58-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: e080ef23035377f2b3ee9cd1e839f8f459bba978\n",
      "\n",
      "Git branch: windef_noisy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,openpiv -g -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of typical parameters\n",
    "window_size = 32  # pixels 32 x 32 pixels interrogation window, in frame A.\n",
    "overlap = 16  # overlap is 8 pixels, i.e. 25% of the window\n",
    "search_size = 40  # pixels 64 x 64 in frame B, avoids some peak locking for \n",
    "                  # large displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openpiv_default_run(im1,im2):\n",
    "    \"\"\" default settings for OpenPIV analysis using\n",
    "    extended_search_area_piv algorithm for two images\n",
    "    \n",
    "    Inputs:\n",
    "        im1,im2 : str,str = path of two image\n",
    "    \"\"\"\n",
    "    frame_a  = tools.imread(im1)\n",
    "    frame_b  = tools.imread(im2)\n",
    "\n",
    "    u, v, sig2noise = pyprocess.extended_search_area_piv(frame_a.astype(np.int32), \n",
    "                                                       frame_b.astype(np.int32), \n",
    "                                                       window_size=window_size, \n",
    "                                                       overlap=overlap, \n",
    "                                                       dt=1, \n",
    "                                                       search_area_size=search_size, \n",
    "                                                       sig2noise_method='peak2mean',\n",
    "                                                       correlation_method='circular',\n",
    "                                                       normalized_correlation=True)\n",
    "    x, y = pyprocess.get_coordinates(frame_a.shape, \n",
    "                                     search_size, \n",
    "                                     overlap)\n",
    "    # 5% lowest range\n",
    "    u, v, mask = validation.sig2noise_val(u, v, \n",
    "                                          sig2noise, \n",
    "                                          threshold = np.percentile(sig2noise,2.5))\n",
    "    u, v = filters.replace_outliers( u, v, method='localmean', \n",
    "                                    max_iter=3, kernel_size=3)\n",
    "    x, y, u, v = scaling.uniform(x, y, u, v, scaling_factor = 1. )\n",
    "\n",
    "    x, y, u, v = tools.transform_coordinates(x, y, u, v)\n",
    "    \n",
    "    tools.save(x, y, u, v, mask, list_of_images[0]+'.txt' )\n",
    "    fig,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "    \n",
    "    tools.display_vector_field(list_of_images[0]+'.txt', \n",
    "                                        on_img=True,image_name=list_of_images[0],\n",
    "                                        scaling_factor=1.,\n",
    "                                        ax=ax[0])\n",
    "    tools.display_vector_field(list_of_images[0]+'.txt', \n",
    "                                        scaling_factor=1.,\n",
    "                                        ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "alist_filter = ['jpg','bmp','png','tif','tiff']\n",
    "\n",
    "\n",
    "# all test cases in /openpiv/examples/\n",
    "list_of_tests = glob.glob('../test*')\n",
    "list_of_tests.sort()\n",
    "\n",
    "list_of_images = []\n",
    "for test in list_of_tests:\n",
    "    \n",
    "    list_of_files = glob.glob(test+'/*.*')\n",
    "    list_of_files.sort()\n",
    "    list_of_images = [f for f in list_of_files if f[-3:] in alist_filter]\n",
    "    if len(list_of_images) > 0:\n",
    "        openpiv_default_run(list_of_images[0],list_of_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python [conda env:openpiv] *",
   "language": "python",
   "name": "conda-env-openpiv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}