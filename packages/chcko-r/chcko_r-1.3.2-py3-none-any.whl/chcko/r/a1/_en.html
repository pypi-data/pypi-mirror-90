%path = "physics/S=E*t"
%kind = 1
%level = 12
<!-- html --><p>A system can be seen as one variable.
A system <em>state</em> is a <em>value</em> of the variable.</p>
<p><strong>Entropy</strong> is the information of a variable.
Entropy is the <em>number of values</em> of the variable.</p>
<p>What value (or state) means is of no importance.
It has been abstracted away.
Only the number counts here.</p>
<p>The values must actually occur.
An elementary change is a value selection.
<strong>Energy</strong> is the <em>number of values per time</em>.</p>
<div class="math notranslate nohighlight">
\[S = Et\]</div>
<p>One can see it the other way around:
Energy brings time into existence by the selections of values.
If the system is composed of many independent variables,
this produces a system time resolution,
that does not exist in any of the independent variables.</p>
<p>A constant amount of energy can either result in</p>
<ul class="simple">
<li><p>a few states cycling fast: <span class="math notranslate nohighlight">\(\Delta S\)</span> and <span class="math notranslate nohighlight">\(\Delta t\)</span> small</p></li>
<li><p>a lot of states cycling slow: <span class="math notranslate nohighlight">\(\Delta S\)</span> and <span class="math notranslate nohighlight">\(\Delta t\)</span> large</p></li>
</ul>
<p>A system often consists of layers.</p>
<p>Assuming an ideal gas,
the energy <span class="math notranslate nohighlight">\(Q=TS\)</span> is given by:</p>
<ul class="simple">
<li><p>the temperature <span class="math notranslate nohighlight">\(T\)</span>: the average kinetic energy of one particle</p></li>
<li><p>the entropy <span class="math notranslate nohighlight">\(S\)</span></p></li>
</ul>
<p>This divides the system in two layers:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(T\)</span> encodes information events (energy) of a layer below.</p></li>
<li><p><span class="math notranslate nohighlight">\(S\)</span> counts the events in the current layer.</p></li>
</ul>
<p>The logarithm in entropy comes up,
when we distribute the information
to more variables of the same kind (e.g. the bit).
In the other direction this is the reason for the exponent <span class="math notranslate nohighlight">\(e^S\)</span>.</p>
<p>The particle’s direction of motion partitions the number <span class="math notranslate nohighlight">\(N\)</span> of particles</p>
<ul class="simple">
<li><p>by direction: factor <span class="math notranslate nohighlight">\(1/2\)</span>, since exclusive</p></li>
<li><p>by orientation: factor <span class="math notranslate nohighlight">\(3\)</span>,
since <span class="math notranslate nohighlight">\(T\)</span>, through averaging,
is acting on all three orientations simultaneously</p></li>
</ul>
<p>Therefore:</p>
<div class="math notranslate nohighlight">
\[Q = ST = 3/2NkT = 3/2RT = 3/2pV\]</div>
<p>For an ideal gas the inner energy is equal to the work done on the surrounding <span class="math notranslate nohighlight">\(3/2 pV\)</span>.</p>
<p>The average energy per particle <span class="math notranslate nohighlight">\(E\)</span> is:</p>
<div class="math notranslate nohighlight">
\[E = 1/2 m v^2 = 3/2 kT\]</div>
<p>Boltzmann’s constant <span class="math notranslate nohighlight">\(k\)</span> is a conversion factor of units of energy.
<span class="math notranslate nohighlight">\(v^2\)</span> can be related better to micro events per time than <span class="math notranslate nohighlight">\(T\)</span>,
but also <span class="math notranslate nohighlight">\(E\)</span> is only the energy in that layer and not the ultimate
unit of information event per time.</p>
<p>The ultimate information event is given by the Planck constant.
The sum of all such events create space and time: E-t, x-v, …</p>
