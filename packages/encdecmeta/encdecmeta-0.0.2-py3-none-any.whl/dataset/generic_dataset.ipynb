{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'GenericDataset' object has no attribute 'overfit'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/work/code/build/lib/dataset/generic_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenericDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/work/code/build/lib/dataset/generic_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fold, config)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATAPATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# overfitting = memorizing one sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'GenericDataset' object has no attribute 'overfit'"]}],"source":["import torch\n","import torch.utils.data\n","import numpy as np\n","import os\n","\n","from utils.load_image import load_image\n","from utils.printing import fancy_print\n","from utils.get_paths import get_paths_for_dataset\n","\n","class GenericDataset(torch.utils.data.Dataset):\n","    def __init__(self,fold, config):\n","        \n","        self.fold = fold\n","        self.debug = config.get('debug', 0)\n","        self.test_run = config.get('test_run', None)\n","        self.img_dir =  os.path.join(os.environ['DATAPATH'],'data', self.fold)\n","        self.label_dir = os.path.join(os.environ['DATAPATH'],'labels', self.fold)\n","\n","        if config.get(self.overfit, False):\n","            self.test_run = 1 # overfitting = memorizing one sample\n","        \n","        self.examples = []\n","        self.samples_dir = os.listdir(self.img_dir)\n","        self.n_samples = len(self.samples_dir)\n","        for fn in self.samples_dir[:self.test_run]:  # important: assumed that file names in  dirs (labels/data) identical\n","            example = {}\n","            example[\"img_path\"] = os.path.join(self.img_dir, fn)\n","            example[\"label_img_path\"] = os.path.join(self.label_dir, fn)\n","            example[\"img_id\"] = fn\n","            self.examples.append(example)\n","        self.num_examples = len(self.examples)\n","\n","\n","        # get values for channel-wise Z-score normalization, by default we use values computed on Cityscapes dataset (full res)\n","        self.norm_R_mean =  config.get('norm_R_mean', 0.2868955263625)        \n","        self.norm_G_mean =  config.get('norm_G_mean', 0.3251330100231946)\n","        self.norm_B_mean =  config.get('norm_B_mean',  0.2838917598962539)\n","        self.norm_R_std =  config.get('norm_R_std', 0.1869226144355443)        \n","        self.norm_G_std =  config.get('norm_G_std', 0.19013295203172015)\n","        self.norm_B_std =  config.get('norm_B_std',  0.18716106284161413)\n","\n","        # if we want to downsample, we have to specify 'H' and 'W' different to the actual image resolution in the configuration file\n","        self.H =   config['H']        \n","        self.W =   config['W']        \n","\n","        if self.debug: \n","            assert fold in ['train', 'val', 'test']\n","            assert len(os.listdir(self.img_dir)[:self.test_run]) == len(os.listdir(self.label_dir)[:self.test_run]), 'Image and label directory must contain an equal number of files.'\n","\n","        if self.debug >1:\n","            message = f'{str.capitalize(fold)} fold contains {self.n_samples} samples.'\n","            if self.test_run:\n","                  message += f' Test run: using only first {self.test_run} samples.'\n","            fancy_print(message)\n","\n","\n","    def __len__(self):\n","        return self.num_examples\n","\n","    def __getitem__(self, index):\n","        example = self.examples[index]\n","        img_path = example[\"img_path\"]\n","        label_img_path = example[\"label_img_path\"]\n","        \n","        \n","        img = load_image(img_path, (self.H, self.W), 'bilinear')\n","        label_img = load_image(label_img_path, (self.H, self.W), 'nearest')\n","\n","        img = img / 255.0\n","        img = img - np.array([self.norm_R_mean, self.norm_G_mean, self.norm_B_mean])\n","        img = img /np.array([self.norm_R_std, self.norm_G_std, self.norm_B_std])\n","        img = np.transpose(img, (2, 0, 1))  # shape: (256, 256, 3) to shape: (3, 256, 256)\n","        img = img.astype(np.float32)    \n","        img = torch.from_numpy(img) \n","        label_img = torch.from_numpy(label_img).long().reshape((self.H,self.W))\n","        #label_img = np.transpose(label_img, (2, 0, 1))  # shape: (256, 256, 3) to shape: (3, 256, 256)\n","\n","        print('dddd', label_img_path, label_img_path)\n","        return (img, label_img)\n","\n","\n","\n","\n","\n","\n","d = GenericDataset('train',{})\n","print(d)\n"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}